{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Re-process all the datasets from parts 1-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmenting the data through generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import time\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from striprtf.striprtf import rtf_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original entries: 143\n",
      "Clean entries: 49\n",
      "Removed 94 entries\n"
     ]
    }
   ],
   "source": [
    "def load_and_clean_jsonl(input_file: str, output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Load JSONL file, remove entries with 'No content provided', and save clean data.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input JSONL file\n",
    "        output_file (str): Path to output clean JSONL file\n",
    "    \"\"\"\n",
    "    # Read the JSONL file\n",
    "    clean_entries = []\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            entry = json.loads(line)\n",
    "            \n",
    "            # Check if the assistant's response is not \"No content provided\"\n",
    "            if entry['messages'][-1]['content'] != \"No content provided\":\n",
    "                clean_entries.append(entry)\n",
    "    \n",
    "    # Save clean entries\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for entry in clean_entries:\n",
    "            f.write(json.dumps(entry) + '\\n')\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Original entries: {count_jsonl_lines(input_file)}\")\n",
    "    print(f\"Clean entries: {len(clean_entries)}\")\n",
    "    print(f\"Removed {count_jsonl_lines(input_file) - len(clean_entries)} entries\")\n",
    "\n",
    "def count_jsonl_lines(file_path: str) -> int:\n",
    "    \"\"\"Count number of lines in JSONL file\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return sum(1 for _ in f)\n",
    "\n",
    "# Execute cleaning\n",
    "input_file = '../data/processed/fine_tuning_data.jsonl'\n",
    "output_file = '../data/processed/clean_fine_tuning_data.jsonl'\n",
    "\n",
    "load_and_clean_jsonl(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of 5 clean entries:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Entry 1:\n",
      "Class: Betting Strategy Techniques\n",
      "Content: The page discusses strategic considerations in a 3-bet pot situation where UTG probes the turn on a 4-straight board. Key points include identifying which hands HJ can fold when faced with a turn prob...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Entry 2:\n",
      "Class: Block-Betting Strategy Techniques\n",
      "Content: **Block-Betting Strategy Techniques in Poker**\n",
      "\n",
      "1. **Definition**: Block-betting is a strategic technique in poker where a player makes a small bet on a particular street to prevent the opponent from ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Entry 3:\n",
      "Class: Block-Betting Strategy Techniques\n",
      "Content: Block-betting strategy is a technique in poker where a player makes a small bet on the river with a medium-strength hand to prevent the opponent from making a large value bet. This strategy aims to co...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Entry 4:\n",
      "Class: Block-Betting Strategy Techniques\n",
      "Content: **Block-Betting Strategy Techniques in Poker**\n",
      "\n",
      "1. **Definition**: Block-betting is a strategy where a player makes a small bet on the river with a moderately strong hand to prevent their opponent fro...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Entry 5:\n",
      "Class: Block-Betting Strategy Techniques\n",
      "Content: Block-betting is a strategic technique in poker where a player makes a small bet on a certain street to prevent their opponent from making a larger bet. This is commonly used on the turn or river to c...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def display_sample_entries(file_path: str, n: int = 5) -> None:\n",
    "    \"\"\"Display first n entries from JSONL file\"\"\"\n",
    "    print(f\"\\nSample of {n} clean entries:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= n:\n",
    "                break\n",
    "            entry = json.loads(line)\n",
    "            # Extract class name without using backslash\n",
    "            class_content = entry['messages'][1]['content']\n",
    "            class_name = class_content.split('Class: ')[1].split('\\n')[0]\n",
    "            \n",
    "            print(f\"\\nEntry {i+1}:\")\n",
    "            print(f\"Class: {class_name}\")\n",
    "            print(f\"Content: {entry['messages'][2]['content'][:200]}...\")\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "display_sample_entries(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full re-augmentation of the data for GTO Poker Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_jsonl(file_path: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"Load clean JSONL and organize by class\"\"\"\n",
    "    class_data = {}\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            entry = json.loads(line)\n",
    "            class_name = entry['messages'][1]['content'].split('Class: ')[1].split('\\n')[0]\n",
    "            content = entry['messages'][2]['content']\n",
    "            \n",
    "            if class_name not in class_data:\n",
    "                class_data[class_name] = []\n",
    "            class_data[class_name].append(content)\n",
    "    \n",
    "    return class_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data_enhanced(class_name: str, num_entries: int = 1) -> List[str]:\n",
    "    \"\"\"Enhanced augmentation focused on practical decision-making with budget constraints\"\"\"\n",
    "    client = OpenAI()\n",
    "    augmented_entries = []\n",
    "    \n",
    "    # Focus on core decision-making scenarios\n",
    "    class_specifics = {\n",
    "        'Betting Strategy Techniques': 'Focus on common bet sizing (33%, 50%, 66%, 75%, pot) decisions.',\n",
    "        'GTO Strategy Techniques': 'Focus on practical approximations and common spot solutions.',\n",
    "        'Equity Analysis': 'Focus on quick equity estimates and common board textures.',\n",
    "        'Range Construction Techniques': 'Focus on practical preflop ranges and common adjustments.',\n",
    "        'Block-Betting Strategy Techniques': 'Focus on river decisions and common stack depths.',\n",
    "        'Blocker and Unblocker Strategies': 'Focus on nuts blockers and key removal effects.',\n",
    "        'Bluff-Catching Strategies': 'Focus on common river spots and bluff frequencies.',\n",
    "        'Stack Strategies': 'Focus on 100BB strategies and common SPR spots.'\n",
    "    }\n",
    "    \n",
    "    extra_prompt = class_specifics.get(class_name, 'Focus on 100BB cash game decisions.')\n",
    "    \n",
    "    system_prompt = \"\"\"You are a practical poker coach helping players make better decisions.\n",
    "    Focus on common situations that players frequently face.\n",
    "    Provide clear decision-making frameworks rather than complex theory.\"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"Create a practical guide for: {class_name}\n",
    "\n",
    "    Requirements:\n",
    "    1. Focus on the most common situations (100BB cash games)\n",
    "    2. Provide ONE specific example with clear decision points\n",
    "    3. Include basic frequencies (e.g., \"bet 66% pot here 80% of the time\")\n",
    "    4. List key factors for making the decision\n",
    "    5. {extra_prompt}\n",
    "\n",
    "    Format as a concise guide of 200-250 words.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=600,  \n",
    "            temperature=0.6, \n",
    "            presence_penalty=0.3,\n",
    "            frequency_penalty=0.3,\n",
    "        )\n",
    "        \n",
    "        entry = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Simplified validation for efficiency\n",
    "        if len(entry.split()) < 150 or len(entry.split()) > 300:\n",
    "            return []\n",
    "            \n",
    "        if not any(term in entry.lower() for term in ['bet', 'call', 'raise', 'fold']):\n",
    "            return []\n",
    "            \n",
    "        augmented_entries.append(entry)\n",
    "        time.sleep(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Generation failed: {str(e)}\")\n",
    "    \n",
    "    return augmented_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_augmentation_needs(consolidated_data: Dict[str, List[str]], target_counts: Dict[str, int]) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Calculate how many new entries are needed for each class.\n",
    "    \n",
    "    Args:\n",
    "        consolidated_data: Current dataset\n",
    "        target_counts: Target number of entries per class\n",
    "    Returns:\n",
    "        Dictionary of class names and number of entries needed\n",
    "    \"\"\"\n",
    "    needs = {}\n",
    "    for class_name, target in target_counts.items():\n",
    "        current_count = len(consolidated_data.get(class_name, []))\n",
    "        if current_count < target:\n",
    "            needs[class_name] = target - current_count\n",
    "    \n",
    "    # Print analysis\n",
    "    print(\"\\nAugmentation Needs Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    for class_name, needed in needs.items():\n",
    "        current = len(consolidated_data.get(class_name, []))\n",
    "        print(f\"{class_name}:\")\n",
    "        print(f\"  Current: {current}\")\n",
    "        print(f\"  Target:  {target_counts[class_name]}\")\n",
    "        print(f\"  Needed:  {needed}\")\n",
    "        print()\n",
    "        \n",
    "    return needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_augmentation(needs: Dict[str, int]) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Perform the actual augmentation using OpenAI API.\n",
    "    \n",
    "    Args:\n",
    "        needs: Dictionary of class names and number of entries needed\n",
    "    Returns:\n",
    "        Dictionary of class names and their new entries\n",
    "    \"\"\"\n",
    "    new_data = {}\n",
    "    total_entries_needed = sum(needs.values())\n",
    "    entries_generated = 0\n",
    "    \n",
    "    print(\"\\nStarting Augmentation Process:\")\n",
    "    print(f\"Total entries needed: {total_entries_needed}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for class_name, needed_count in needs.items():\n",
    "        print(f\"\\nProcessing: {class_name}\")\n",
    "        print(f\"Entries needed: {needed_count}\")\n",
    "        \n",
    "        new_entries = []\n",
    "        while len(new_entries) < needed_count:\n",
    "            entries = augment_data_enhanced(class_name)\n",
    "            if entries:\n",
    "                new_entries.extend(entries)\n",
    "                entries_generated += len(entries)\n",
    "                print(f\"Progress: {len(new_entries)}/{needed_count} entries\")\n",
    "                print(f\"Total progress: {entries_generated}/{total_entries_needed}\")\n",
    "            time.sleep(1)\n",
    "        \n",
    "        new_data[class_name] = new_entries\n",
    "        \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_all_classes(consolidated_data: Dict[str, List[str]], target_counts: Dict[str, int]) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Orchestrate the entire augmentation process.\n",
    "    \n",
    "    Args:\n",
    "        consolidated_data: Current dataset\n",
    "        target_counts: Target number of entries per class\n",
    "    Returns:\n",
    "        Updated dataset with new entries\n",
    "    \"\"\"\n",
    "    # 1. Calculate needs (no API calls)\n",
    "    needs = calculate_augmentation_needs(consolidated_data, target_counts)\n",
    "    \n",
    "    # 2. Confirm before making API calls\n",
    "    total_needed = sum(needs.values())\n",
    "    if total_needed > 0:\n",
    "        print(f\"\\nTotal entries to generate: {total_needed}\")\n",
    "        proceed = input(\"Proceed with augmentation? (y/n): \")\n",
    "        if proceed.lower() != 'y':\n",
    "            print(\"Augmentation cancelled\")\n",
    "            return consolidated_data\n",
    "    \n",
    "    # 3. Perform augmentation (API calls)\n",
    "    new_data = perform_augmentation(needs)\n",
    "    \n",
    "    # 4. Merge results (no API calls)\n",
    "    result = consolidated_data.copy()\n",
    "    for class_name, new_entries in new_data.items():\n",
    "        if class_name in result:\n",
    "            result[class_name].extend(new_entries)\n",
    "        else:\n",
    "            result[class_name] = new_entries\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target counts for robust fine-tuning\n",
    "TARGET_COUNTS = {\n",
    "    'Betting Strategy Techniques': 30,      # Core concept\n",
    "    'Block-Betting Strategy Techniques': 20,\n",
    "    'Blocker and Unblocker Strategies': 20,\n",
    "    'Bluff-Catching Strategies': 20,\n",
    "    'Equity Analysis': 30,                  # Core concept\n",
    "    'Flop Shoving Strategies': 20,\n",
    "    'GTO Strategy Techniques': 30,          # Core concept\n",
    "    'Monotone Board Strategy': 20,\n",
    "    'Other Strategies and Analyses': 30,    # Diverse content\n",
    "    'Out-of-Position Strategies': 20,\n",
    "    'Poker Fundamentals and Soft Skills': 30, # Core concept\n",
    "    'Range Construction Techniques': 30,      # Core concept\n",
    "    'Stack Strategies': 20,\n",
    "    'Squeezing and Setmining Strategies': 20,\n",
    "    'Straddle Strategy Analysis': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentation Needs Analysis:\n",
      "----------------------------------------\n",
      "Betting Strategy Techniques:\n",
      "  Current: 1\n",
      "  Target:  30\n",
      "  Needed:  29\n",
      "\n",
      "Block-Betting Strategy Techniques:\n",
      "  Current: 4\n",
      "  Target:  20\n",
      "  Needed:  16\n",
      "\n",
      "Blocker and Unblocker Strategies:\n",
      "  Current: 3\n",
      "  Target:  20\n",
      "  Needed:  17\n",
      "\n",
      "Bluff-Catching Strategies:\n",
      "  Current: 4\n",
      "  Target:  20\n",
      "  Needed:  16\n",
      "\n",
      "Equity Analysis:\n",
      "  Current: 0\n",
      "  Target:  30\n",
      "  Needed:  30\n",
      "\n",
      "Flop Shoving Strategies:\n",
      "  Current: 4\n",
      "  Target:  20\n",
      "  Needed:  16\n",
      "\n",
      "GTO Strategy Techniques:\n",
      "  Current: 3\n",
      "  Target:  30\n",
      "  Needed:  27\n",
      "\n",
      "Monotone Board Strategy:\n",
      "  Current: 4\n",
      "  Target:  20\n",
      "  Needed:  16\n",
      "\n",
      "Other Strategies and Analyses:\n",
      "  Current: 2\n",
      "  Target:  30\n",
      "  Needed:  28\n",
      "\n",
      "Out-of-Position Strategies:\n",
      "  Current: 4\n",
      "  Target:  20\n",
      "  Needed:  16\n",
      "\n",
      "Poker Fundamentals and Soft Skills:\n",
      "  Current: 4\n",
      "  Target:  30\n",
      "  Needed:  26\n",
      "\n",
      "Range Construction Techniques:\n",
      "  Current: 1\n",
      "  Target:  30\n",
      "  Needed:  29\n",
      "\n",
      "Stack Strategies:\n",
      "  Current: 0\n",
      "  Target:  20\n",
      "  Needed:  20\n",
      "\n",
      "Squeezing and Setmining Strategies:\n",
      "  Current: 3\n",
      "  Target:  20\n",
      "  Needed:  17\n",
      "\n",
      "Straddle Strategy Analysis:\n",
      "  Current: 4\n",
      "  Target:  20\n",
      "  Needed:  16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consolidated_data = load_clean_jsonl('../data/processed/clean_fine_tuning_data.jsonl')\n",
    "\n",
    "needs = calculate_augmentation_needs(consolidated_data, TARGET_COUNTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm and perform augmentation\n",
    "total_needed = sum(needs.values())\n",
    "if total_needed > 0:\n",
    "    print(f\"\\nTotal entries to generate: {total_needed}\")\n",
    "    proceed = input(\"Proceed with augmentation? (y/n): \")\n",
    "    if proceed.lower() == 'y':\n",
    "        new_data = perform_augmentation(needs)\n",
    "        \n",
    "        # Save the augmented data\n",
    "        with open('../data/processed/new_augmented_data.jsonl', 'w', encoding='utf-8') as f:\n",
    "            for class_name, entries in new_data.items():\n",
    "                for entry in entries:\n",
    "                    messages = [\n",
    "                        {\"role\": \"system\", \"content\": \"You are an expert poker strategist.\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"Explain: {class_name}\"},\n",
    "                        {\"role\": \"assistant\", \"content\": entry}\n",
    "                    ]\n",
    "                    json.dump({\"messages\": messages}, f)\n",
    "                    f.write('\\n')\n",
    "        print(\"Augmented data saved to '../data/processed/new_augmented_data.jsonl'\")\n",
    "    else:\n",
    "        print(\"Augmentation cancelled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmenting the data through book context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from time import sleep\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Class Name  \\\n",
      "0                     terminology introduction   \n",
      "1          poker strategy lessons introduction   \n",
      "2               new class - poker fundamentals   \n",
      "3                 new class - poker variations   \n",
      "4  new class - poker session review techniques   \n",
      "\n",
      "                                         Explanation  \\\n",
      "0  This class contains introductory content that ...   \n",
      "1  This class contains introductory content that ...   \n",
      "2  This class contains content that introduces fu...   \n",
      "3  This class contains content that introduces an...   \n",
      "4  This class focuses on techniques and strategie...   \n",
      "\n",
      "                                   Processed Content  \n",
      "0  The page introduces various poker terminologie...  \n",
      "1                                No content provided  \n",
      "2                                No content provided  \n",
      "3                                No content provided  \n",
      "4                                No content provided  \n"
     ]
    }
   ],
   "source": [
    "# Previous Code\n",
    "# Define the path to the RTF file\n",
    "rtf_path = \"../data/raw/output.rtf\"\n",
    "\n",
    "# Read the .rtf file and extract its content\n",
    "with open(rtf_path, 'r') as file:\n",
    "    rtf_content = file.read()\n",
    "\n",
    "# Convert RTF content to plain text\n",
    "plain_text = rtf_to_text(rtf_content)\n",
    "\n",
    "# Split the plain text into chunks based on \"Added new class:\"\n",
    "entries = re.split(r\"Added new class:\", plain_text)\n",
    "\n",
    "# Initialize a list to store processed data\n",
    "processed_data = []\n",
    "\n",
    "# Iterate over each entry to extract information\n",
    "for entry in entries:\n",
    "    if not entry.strip():\n",
    "        continue  # Skip empty entries\n",
    "\n",
    "    # Extract Class Name\n",
    "    class_match = re.search(r\"^(.*)\\n\", entry)\n",
    "    class_name = class_match.group(1).strip() if class_match else \"Unknown\"\n",
    "\n",
    "    # Extract Explanation\n",
    "    explanation_match = re.search(r\"Explanation:(.*?)(The page|The content|$)\", entry, re.S)\n",
    "    explanation = explanation_match.group(1).strip() if explanation_match else \"No explanation provided\"\n",
    "\n",
    "    # Extract Processed Content\n",
    "    content_match = re.search(r\"(The page.*)\", entry, re.S)\n",
    "    processed_content = content_match.group(1).strip() if content_match else \"No content provided\"\n",
    "\n",
    "    # Append the extracted information to the list\n",
    "    processed_data.append({\n",
    "        \"Class Name\": class_name,\n",
    "        \"Explanation\": explanation,\n",
    "        \"Processed Content\": processed_content\n",
    "    })\n",
    "\n",
    "# Convert the processed data to a DataFrame\n",
    "df = pd.DataFrame(processed_data)\n",
    "\n",
    "# Display the first few rows to verify the data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample current_class:\n",
      "terminology introduction: This class contains introductory content that outlines and introduces the reader to important poker terminology and concepts. It is aimed at familiarizing the reader with common terms used throughout the book.\n",
      "poker strategy lessons introduction: This class contains introductory content that outlines the structure and purpose of the poker lessons in the book. It is aimed at informing the reader about the systematic approach and the focus on game theory optimal strategies.\n",
      "The book contains 334 poker lessons focused on game theory optimal strategies, organized by theme to enhance skill progression.\n",
      "new class - poker fundamentals: This class contains content that introduces fundamental concepts and skills essential for playing poker effectively. It focuses on the basic mental and strategic skills necessary for managing one's gameplay and emotions.\n",
      "new class - poker variations: This class contains content that introduces and describes the different formats and variations of poker games. It aims to familiarize the reader with the diverse types of poker games available, encouraging them to identify a format that suits their preferences and skills.\n",
      "Poker is a type of game with many formats like MTT's, SNG's, cash games, heads up, and fullring games. Players should find the format that suits them best.\n",
      "new class - poker session review techniques: This class focuses on techniques and strategies for reviewing and analyzing poker sessions. It provides guidance on how to systematically evaluate past games to identify areas for improvement, enhance understanding of game dynamics, and develop better strategic insights for future play.\n",
      "\n",
      "Sample current_data:\n",
      "terminology introduction: 1 entries\n",
      "poker strategy lessons introduction: 1 entries\n",
      "new class - poker fundamentals: 1 entries\n",
      "new class - poker variations: 1 entries\n",
      "new class - poker session review techniques: 1 entries\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Create a mapping from class names to their explanations\n",
    "current_class = dict(zip(df['Class Name'], df['Explanation']))\n",
    "\n",
    "# Create a mapping from class names to lists of processed content\n",
    "current_data = defaultdict(list)\n",
    "for _, row in df.iterrows():\n",
    "    class_name = row['Class Name']\n",
    "    content = row['Processed Content']\n",
    "    current_data[class_name].append(content)\n",
    "\n",
    "# Verify the contents\n",
    "print(\"Sample current_class:\")\n",
    "for key, value in list(current_class.items())[:5]:\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nSample current_data:\")\n",
    "for key, value in list(current_data.items())[:5]:\n",
    "    print(f\"{key}: {len(value)} entries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the comprehensive class mapping\n",
    "class_mapping = {\n",
    "    # -------------------------\n",
    "    # Fundamentals\n",
    "    # -------------------------\n",
    "    'new class - poker fundamentals': 'Poker Fundamentals and Soft Skills',\n",
    "    'new class - poker fundamentals and soft skills': 'Poker Fundamentals and Soft Skills',\n",
    "    'terminology introduction': 'Fundamentals and Soft Skills',\n",
    "\n",
    "    # -------------------------\n",
    "    # Betting Strategies\n",
    "    # -------------------------\n",
    "    'new class - betting strategy techniques': 'Betting Strategy Techniques',\n",
    "    'new class - bet sizing strategy techniques': 'Betting Strategy Techniques',\n",
    "    'new class - c-betting strategy in 3-bet pots': 'Betting Strategy Techniques',\n",
    "    'new class - c-betting strategy in mtts': 'Betting Strategy Techniques',\n",
    "    'new class - delayed c-betting strategy techniques': 'Betting Strategy Techniques',\n",
    "    'new class - flop 3-betting strategy techniques': 'Betting Strategy Techniques',\n",
    "    'new class - 3-bet pot defense techniques': 'Betting Strategy Techniques',\n",
    "    'new class - 4-bet strategy techniques': 'Betting Strategy Techniques',\n",
    "    'new class - 4-straight board defense techniques': 'Betting Strategy Techniques',\n",
    "    'new class - preflop 3-bet strategy': 'Betting Strategy Techniques',\n",
    "    'new class - raising and calling strategy techniques': 'Betting Strategy Techniques',\n",
    "\n",
    "    # -------------------------\n",
    "    # Bluff-Catching Strategies\n",
    "    # -------------------------\n",
    "    'new class - bluff-catching techniques': 'Bluff-Catching Strategies',\n",
    "    'new class - semi-bluff and defense dynamics': 'Bluff-Catching Strategies',\n",
    "\n",
    "    # -------------------------\n",
    "    # Range Construction\n",
    "    # -------------------------\n",
    "    'new class - range construction techniques': 'Range Construction Techniques',\n",
    "    'new class - checking range construction techniques': 'Range Construction Techniques',\n",
    "    'checking range construction techniques': 'Range Construction Techniques',\n",
    "    'new class - probing range construction techniques': 'Range Construction Techniques',\n",
    "    'new class - range analysis techniques': 'Range Construction Techniques',\n",
    "\n",
    "    # -------------------------\n",
    "    # Blocker and Unblocker Strategies\n",
    "    # -------------------------\n",
    "    'new class - blocker analysis techniques': 'Blocker and Unblocker Strategies',\n",
    "    'new class - blocker and range strategy techniques': 'Blocker and Unblocker Strategies',\n",
    "    'new class - unblocker strategy analysis': 'Blocker and Unblocker Strategies',\n",
    "    'new class - unblocker and blocker strategy techniques': 'Blocker and Unblocker Strategies',\n",
    "\n",
    "    # -------------------------\n",
    "    # GTO Strategies\n",
    "    # -------------------------\n",
    "    'new class - gto concepts and application': 'GTO Strategy Techniques',\n",
    "    'new class - gto strategy training techniques': 'GTO Strategy Techniques',\n",
    "    'new class - custom gto solution training techniques': 'GTO Strategy Techniques',\n",
    "\n",
    "    # -------------------------\n",
    "    # Equity Analysis\n",
    "    # -------------------------\n",
    "    'new class - equity analysis techniques': 'Equity Analysis',\n",
    "    'new class - equity realization techniques': 'Equity Analysis',\n",
    "    'new class - equity distribution analysis': 'Equity Analysis',\n",
    "    'new class - equity realization and stack depth analysis': 'Equity Analysis',\n",
    "    'new class - equity realization and decision-making analysis': 'Equity Analysis',\n",
    "    'new class - equity bucket strategy techniques': 'Equity Analysis',\n",
    "    'new class - equity introduction': 'Equity Analysis',\n",
    "    'new class - backdoor equity analysis': 'Equity Analysis',\n",
    "    'new class - board texture analysis': 'Equity Analysis',\n",
    "    'new class - implied odds analysis': 'Equity Analysis',\n",
    "    'new class - post-flop analysis': 'Equity Analysis',\n",
    "\n",
    "    # -------------------------\n",
    "    # Poker Variations and Formats\n",
    "    # -------------------------\n",
    "    'new class - poker variations': 'Poker Variations and Formats',\n",
    "    'new class - toy game strategy analysis': 'Poker Variations and Formats',\n",
    "\n",
    "    # -------------------------\n",
    "    # Session and Hand Analysis\n",
    "    # -------------------------\n",
    "    'new class - poker session review techniques': 'Poker Session Review and Hand Analysis',\n",
    "    'new class - poker hand analysis': 'Poker Session Review and Hand Analysis',\n",
    "\n",
    "    # -------------------------\n",
    "    # Stack Strategies\n",
    "    # -------------------------\n",
    "    'new class - shortstack play techniques': 'Stack Strategies',\n",
    "    'new class - shallow stack strategy techniques': 'Stack Strategies',\n",
    "    'new class - short stack limping strategy': 'Stack Strategies',\n",
    "    'new class - short stack turn shove strategy': 'Stack Strategies',\n",
    "    'new class - bankroll management techniques': 'Stack Strategies',\n",
    "    'new class - deep stack strategy techniques': 'Stack Strategies',\n",
    "\n",
    "    # -------------------------\n",
    "    # Squeezing and Setmining Strategies\n",
    "    # -------------------------\n",
    "    'new class - squeezing strategy techniques': 'Squeezing and Setmining Strategies',\n",
    "    'new class - setmining strategy techniques': 'Squeezing and Setmining Strategies',\n",
    "    'new class - trip board turn strategy': 'Squeezing and Setmining Strategies',\n",
    "\n",
    "    # -------------------------\n",
    "    # Other Strategies and Analyses\n",
    "    # -------------------------\n",
    "    'new class - minimum defense frequency (mdf) strategy techniques': 'Other Strategies and Analyses',\n",
    "    'new class - nash distance and exploitation analysis': 'Other Strategies and Analyses',\n",
    "    'new class - freerolling strategy analysis': 'Other Strategies and Analyses',\n",
    "    'new class - strategic domination theory': 'Other Strategies and Analyses',\n",
    "    'new class - stack depth strategy analysis': 'Other Strategies and Analyses',\n",
    "    'new class - range morphology techniques': 'Other Strategies and Analyses',\n",
    "    'new class - chop board strategy analysis': 'Other Strategies and Analyses',\n",
    "    'new class - countering range-bets strategies': 'Other Strategies and Analyses',\n",
    "    'new class - overbet strategy techniques': 'Other Strategies and Analyses',\n",
    "    'new class - turn barreling strategy techniques': 'Other Strategies and Analyses',\n",
    "    'new class - polarization strategy techniques': 'Other Strategies and Analyses',\n",
    "    'new class - icm decision-making analysis': 'Other Strategies and Analyses',\n",
    "    'new class - double-barrel defense on monotone flops': 'Other Strategies and Analyses',\n",
    "    'new class - river barreling strategy techniques': 'Other Strategies and Analyses',\n",
    "    'new class - tactics analysis': 'Other Strategies and Analyses',\n",
    "    'new class - threshold analysis techniques': 'Other Strategies and Analyses',\n",
    "    'new class - value betting and trap strategy analysis': 'Other Strategies and Analyses',\n",
    "    'new class - variance and expectation management': 'Other Strategies and Analyses',\n",
    "    'new class - btn river strategy techniques': 'Other Strategies and Analyses',\n",
    "    'new class - advanced poker concepts': 'Other Strategies and Analyses',\n",
    "    'new class - check-raise barreling strategy techniques': 'Other Strategies and Analyses',\n",
    "    'new class - depolarized turn probe strategy techniques': 'Other Strategies and Analyses',\n",
    "    'new class - expected value analysis': 'Other Strategies and Analyses',\n",
    "    'new class - exploitability and defense techniques': 'Other Strategies and Analyses',\n",
    "    'new class - indifference analysis techniques': 'Other Strategies and Analyses',\n",
    "    'new class - merge strategy techniques': 'Other Strategies and Analyses',\n",
    "\n",
    "    # -------------------------\n",
    "    # Straddle Strategy Analysis\n",
    "    # -------------------------\n",
    "    'new class - straddle theory analysis': 'Straddle Strategy Analysis',\n",
    "    'new class - straddle strategy techniques': 'Straddle Strategy Analysis',\n",
    "\n",
    "    # -------------------------\n",
    "    # Flop Shoving Strategies\n",
    "    # -------------------------\n",
    "    'new class - flop shoving strategy in spin & go': 'Flop Shoving Strategies',\n",
    "    'new class - flop shoving strategy in heads-up sit & go': 'Flop Shoving Strategies',\n",
    "\n",
    "    # -------------------------\n",
    "    # Block-Betting Strategy Techniques\n",
    "    # -------------------------\n",
    "    'new class - block-betting strategy techniques': 'Block-Betting Strategy Techniques',\n",
    "    'new class - block-betting and river decision strategies': 'Block-Betting Strategy Techniques',\n",
    "\n",
    "    # -------------------------\n",
    "    # Poker Humor and Memes\n",
    "    # -------------------------\n",
    "    'new class - poker humor and memes': 'Poker Humor and Memes',\n",
    "\n",
    "    # -------------------------\n",
    "    # Monotone Board Strategy\n",
    "    # -------------------------\n",
    "    'new class - monotone flop strategy': 'Monotone Board Strategy',\n",
    "    'new class - monotone board strategy': 'Monotone Board Strategy',\n",
    "\n",
    "    # -------------------------\n",
    "    # Hand History Analysis\n",
    "    # -------------------------\n",
    "    'new class - hand history analysis': 'Hand History Analysis',\n",
    "\n",
    "    # -------------------------\n",
    "    # Mixing Strategy Techniques\n",
    "    # -------------------------\n",
    "    'new class - mixing strategy techniques': 'Mixing Strategy Techniques',\n",
    "\n",
    "    # -------------------------\n",
    "    # Donking Strategy Techniques\n",
    "    # -------------------------\n",
    "    'new class - donking strategy techniques': 'Donking Strategy Techniques',\n",
    "\n",
    "    # -------------------------\n",
    "    # Triple-Barrel Bluffing Strategy\n",
    "    # -------------------------\n",
    "    'new class - triple-barrel bluffing strategy': 'Triple-Barrel Bluffing Strategy',\n",
    "\n",
    "    # -------------------------\n",
    "    # Check-Raising Strategy Techniques\n",
    "    # -------------------------\n",
    "    'new class - check-raising strategy techniques': 'Check-Raising Strategy Techniques',\n",
    "\n",
    "    # -------------------------\n",
    "    # Rake Structure Analysis\n",
    "    # -------------------------\n",
    "    'new class - rake structure analysis': 'Rake Structure Analysis',\n",
    "\n",
    "    # -------------------------\n",
    "    # Push-Folding Strategy Analysis\n",
    "    # -------------------------\n",
    "    'new class - push-folding strategy analysis': 'Push-Folding Strategy Analysis',\n",
    "\n",
    "    # -------------------------\n",
    "    # Offense vs Defense Strategy Techniques\n",
    "    # -------------------------\n",
    "    'new class - offense vs defense strategy techniques': 'Offense vs Defense Strategy Techniques',\n",
    "\n",
    "    # -------------------------\n",
    "    # Out-of-Position Strategies\n",
    "    # -------------------------\n",
    "    'new class - out-of-position turn strategy techniques': 'Out-of-Position Strategies',\n",
    "    'new class - out-of-position value betting techniques': 'Out-of-Position Strategies',\n",
    "\n",
    "    # -------------------------\n",
    "    # Poker Strategy Lessons\n",
    "    # -------------------------\n",
    "    'poker strategy lessons introduction': 'Poker Strategy Lessons',\n",
    "}\n",
    "\n",
    "# Ensure all keys are in lowercase for consistent mapping\n",
    "class_mapping = {k.lower(): v for k, v in class_mapping.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Class Name  \\\n",
      "0                            terminology introduction   \n",
      "1                 poker strategy lessons introduction   \n",
      "2                      new class - poker fundamentals   \n",
      "3                        new class - poker variations   \n",
      "4         new class - poker session review techniques   \n",
      "..                                                ...   \n",
      "93                    new class - equity introduction   \n",
      "94  new class - custom GTO solution training techn...   \n",
      "95                       new class - tactics analysis   \n",
      "96  new class - offense vs defense strategy techni...   \n",
      "97  new class - check-raise barreling strategy tec...   \n",
      "\n",
      "                        Consolidated Class  \n",
      "0             Fundamentals and Soft Skills  \n",
      "1                   Poker Strategy Lessons  \n",
      "2       Poker Fundamentals and Soft Skills  \n",
      "3             Poker Variations and Formats  \n",
      "4   Poker Session Review and Hand Analysis  \n",
      "..                                     ...  \n",
      "93                         Equity Analysis  \n",
      "94                 GTO Strategy Techniques  \n",
      "95           Other Strategies and Analyses  \n",
      "96  Offense vs Defense Strategy Techniques  \n",
      "97           Other Strategies and Analyses  \n",
      "\n",
      "[98 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the DataFrame for consolidation\n",
    "df_consolidated = df.copy()\n",
    "\n",
    "# Normalize the 'Class Name' by converting to lowercase and stripping whitespace\n",
    "df_consolidated['Class Name Lower'] = df_consolidated['Class Name'].str.lower().str.strip()\n",
    "\n",
    "# Apply the mapping to create 'Consolidated Class'\n",
    "df_consolidated['Consolidated Class'] = df_consolidated['Class Name Lower'].map(class_mapping).fillna(df_consolidated['Class Name'])\n",
    "\n",
    "# Drop the temporary 'Class Name Lower' column\n",
    "df_consolidated.drop('Class Name Lower', axis=1, inplace=True)\n",
    "\n",
    "# Verify the consolidation by displaying unique class mappings\n",
    "print(df_consolidated[['Class Name', 'Consolidated Class']].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consolidated Data Entry Counts:\n",
      "Betting Strategy Techniques: 11 entries\n",
      "Block-Betting Strategy Techniques: 2 entries\n",
      "Blocker and Unblocker Strategies: 4 entries\n",
      "Bluff-Catching Strategies: 2 entries\n",
      "Check-Raising Strategy Techniques: 1 entries\n",
      "Donking Strategy Techniques: 1 entries\n",
      "Equity Analysis: 11 entries\n",
      "Flop Shoving Strategies: 2 entries\n",
      "Fundamentals and Soft Skills: 1 entries\n",
      "GTO Strategy Techniques: 3 entries\n",
      "Hand History Analysis: 1 entries\n",
      "Mixing Strategy Techniques: 1 entries\n",
      "Monotone Board Strategy: 2 entries\n",
      "Offense vs Defense Strategy Techniques: 1 entries\n",
      "Other Strategies and Analyses: 26 entries\n",
      "Out-of-Position Strategies: 2 entries\n",
      "Poker Fundamentals and Soft Skills: 2 entries\n",
      "Poker Humor and Memes: 1 entries\n",
      "Poker Session Review and Hand Analysis: 2 entries\n",
      "Poker Strategy Lessons: 1 entries\n",
      "Poker Variations and Formats: 2 entries\n",
      "Push-Folding Strategy Analysis: 1 entries\n",
      "Rake Structure Analysis: 1 entries\n",
      "Range Construction Techniques: 5 entries\n",
      "Squeezing and Setmining Strategies: 3 entries\n",
      "Stack Strategies: 6 entries\n",
      "Straddle Strategy Analysis: 2 entries\n",
      "Triple-Barrel Bluffing Strategy: 1 entries\n"
     ]
    }
   ],
   "source": [
    "# Group processed content by consolidated class\n",
    "grouped = df_consolidated.groupby('Consolidated Class')['Processed Content'].apply(list).reset_index()\n",
    "\n",
    "# Convert to a dictionary for easier handling\n",
    "consolidated_data = dict(zip(grouped['Consolidated Class'], grouped['Processed Content']))\n",
    "\n",
    "# Verify the consolidation by printing the number of entries per class\n",
    "print(\"\\nConsolidated Data Entry Counts:\")\n",
    "for class_name, entries in consolidated_data.items():\n",
    "    print(f\"{class_name}: {len(entries)} entries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Additional examples needed per class:\n",
      "Betting Strategy Techniques: 4\n",
      "Block-Betting Strategy Techniques: 13\n",
      "Blocker and Unblocker Strategies: 11\n",
      "Bluff-Catching Strategies: 13\n",
      "Check-Raising Strategy Techniques: 14\n",
      "Donking Strategy Techniques: 14\n",
      "Equity Analysis: 4\n",
      "Flop Shoving Strategies: 13\n",
      "Fundamentals and Soft Skills: 14\n",
      "GTO Strategy Techniques: 12\n",
      "Hand History Analysis: 14\n",
      "Mixing Strategy Techniques: 14\n",
      "Monotone Board Strategy: 13\n",
      "Offense vs Defense Strategy Techniques: 14\n",
      "Out-of-Position Strategies: 13\n",
      "Poker Fundamentals and Soft Skills: 13\n",
      "Poker Humor and Memes: 14\n",
      "Poker Session Review and Hand Analysis: 13\n",
      "Poker Strategy Lessons: 14\n",
      "Poker Variations and Formats: 13\n",
      "Push-Folding Strategy Analysis: 14\n",
      "Rake Structure Analysis: 14\n",
      "Range Construction Techniques: 10\n",
      "Squeezing and Setmining Strategies: 12\n",
      "Stack Strategies: 9\n",
      "Straddle Strategy Analysis: 13\n",
      "Triple-Barrel Bluffing Strategy: 14\n"
     ]
    }
   ],
   "source": [
    "# Set minimum desired examples per class (e.g., 10)\n",
    "MIN_EXAMPLES = 15\n",
    "\n",
    "# Calculate needed examples for each class\n",
    "needs = {}\n",
    "for class_name, entries in consolidated_data.items():\n",
    "    current_count = len(entries)\n",
    "    if current_count < MIN_EXAMPLES:\n",
    "        needs[class_name] = MIN_EXAMPLES - current_count\n",
    "\n",
    "print(\"\\nAdditional examples needed per class:\")\n",
    "for class_name, needed in needs.items():\n",
    "    print(f\"{class_name}: {needed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content(prompt, model=\"gpt-4\", max_retries=3):\n",
    "    \"\"\"Generate content using OpenAI API with retry logic\"\"\"\n",
    "    client = openai.OpenAI()  # Create client instance\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(  # Updated API call\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert poker strategist specializing in GTO concepts.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_tokens=700\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"Failed after {max_retries} attempts: {e}\")\n",
    "                return None\n",
    "            print(f\"Attempt {attempt + 1} failed, retrying... Error: {e}\")\n",
    "            sleep(5)  # Wait 5 seconds before retrying\n",
    "\n",
    "def perform_augmentation(needs_dict):\n",
    "    augmented_data = []\n",
    "    \n",
    "    for class_name, num_needed in needs_dict.items():\n",
    "        print(f\"\\nProcessing {class_name}: generating {num_needed} new examples\")\n",
    "        \n",
    "        # Get existing content for this class from df_consolidated\n",
    "        class_content = df_consolidated[df_consolidated['Consolidated Class'] == class_name]\n",
    "        \n",
    "        # Get both original class names and their content for context\n",
    "        original_examples = []\n",
    "        for _, row in class_content.iterrows():\n",
    "            original_examples.append(f\"Original Class: {row['Class Name']}\\nContent: {row['Processed Content']}\")\n",
    "        \n",
    "        context = \"\\n\\n\".join(original_examples)\n",
    "        \n",
    "        for i in range(num_needed):\n",
    "            prompt = f\"\"\"Based on these existing poker strategy explanations for {class_name}:\n",
    "\n",
    "            {context}\n",
    "\n",
    "            Generate a new, unique explanation that:\n",
    "            1. Maintains consistency with the original content\n",
    "            2. Uses different examples or scenarios\n",
    "            3. Preserves the technical accuracy of poker concepts\n",
    "            4. Follows the same depth of strategic analysis\n",
    "            5. Maintains the GTO-focused perspective\n",
    "\n",
    "            Generate a concise but comprehensive explanation.\"\"\"\n",
    "            \n",
    "            new_content = generate_content(prompt)\n",
    "            \n",
    "            if new_content:\n",
    "                # Create JSONL entry in the required format\n",
    "                entry = {\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are an expert poker strategist specializing in GTO concepts.\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"Explain the following poker strategy concept:\\nClass: {class_name}\\nConcept:\"},\n",
    "                        {\"role\": \"assistant\", \"content\": new_content}\n",
    "                    ]\n",
    "                }\n",
    "                augmented_data.append(entry)\n",
    "                print(f\"Generated example {i+1}/{num_needed} for {class_name}\")\n",
    "            \n",
    "            # Add a small delay between requests to avoid rate limits\n",
    "            sleep(1)\n",
    "    \n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total needed examples across all classes\n",
    "total_needed = sum(needs.values())\n",
    "\n",
    "# Execute augmentation and save results\n",
    "if total_needed > 0:\n",
    "    print(f\"\\nTotal entries to generate: {total_needed}\")\n",
    "    proceed = input(\"Proceed with augmentation? (y/n): \")\n",
    "    \n",
    "    if proceed.lower() == 'y':\n",
    "        # Perform augmentation\n",
    "        new_data = perform_augmentation(needs)\n",
    "        \n",
    "        # Save the augmented data\n",
    "        output_path = '../data/processed/contexted_augmented_data.jsonl'\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            for entry in new_data:\n",
    "                json.dump(entry, f)\n",
    "                f.write('\\n')\n",
    "        \n",
    "        print(f\"\\nAugmented data saved to {output_path}\")\n",
    "        print(f\"Generated {len(new_data)} new examples\")\n",
    "    else:\n",
    "        print(\"Augmentation cancelled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine with other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_save_jsonl(input_file: str, output_file: str = None):\n",
    "    \"\"\"Clean JSONL file and save corrected version\"\"\"\n",
    "    if output_file is None:\n",
    "        output_file = input_file.replace('.jsonl', '_cleaned.jsonl')\n",
    "    \n",
    "    cleaned_data = []\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                # Remove invalid escape characters\n",
    "                cleaned_line = line.replace('\\\\', '\\\\\\\\')\n",
    "                # Parse and re-serialize to ensure valid JSON\n",
    "                entry = json.loads(cleaned_line)\n",
    "                cleaned_data.append(entry)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error processing line: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Save cleaned data\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for entry in cleaned_data:\n",
    "            json.dump(entry, f)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"Cleaned {len(cleaned_data)} entries saved to {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "def load_and_validate_data(file_paths: List[str]) -> List[Dict]:\n",
    "    \"\"\"Load and validate multiple JSONL files for fine-tuning with error handling\"\"\"\n",
    "    all_data = []\n",
    "    for file_path in file_paths:\n",
    "        print(f\"\\nProcessing {file_path}:\")\n",
    "        file_data = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f, 1):\n",
    "                try:\n",
    "                    entry = json.loads(line.strip())\n",
    "                    if 'messages' in entry:\n",
    "                        file_data.append(entry)\n",
    "                    else:\n",
    "                        print(f\"Line {i}: Missing 'messages' key\")\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error in {file_path}, line {i}:\")\n",
    "                    print(f\"Content: {line[:100]}...\")\n",
    "                    print(f\"Error: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        print(f\"Successfully loaded {len(file_data)} valid entries\")\n",
    "        all_data.extend(file_data)\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "def analyze_class_distribution(data: List[Dict]) -> pd.DataFrame:\n",
    "    \"\"\"Analyze the distribution of classes in the dataset\"\"\"\n",
    "    classes = []\n",
    "    for entry in data:\n",
    "        user_msg = [m for m in entry['messages'] if m['role'] == 'user'][0]['content']\n",
    "        if 'Class:' in user_msg:\n",
    "            class_name = user_msg.split('Class:')[1].split('\\n')[0].strip()\n",
    "            classes.append(class_name)\n",
    "    \n",
    "    distribution = pd.DataFrame(pd.Series(classes).value_counts()).reset_index()\n",
    "    distribution.columns = ['Class', 'Count']\n",
    "    return distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up fine-tuning environment...\n",
      "Error processing line: Expecting ',' delimiter: line 1 column 523 (char 522)\n",
      "Error processing line: Expecting ',' delimiter: line 1 column 513 (char 512)\n",
      "Cleaned 260 entries saved to ../data/processed/2-internet_tutorials_cleaned.jsonl\n",
      "Cleaned 8 entries saved to ../data/processed/3-late_game_training_cleaned.jsonl\n",
      "\n",
      "Processing ../data/processed/1-contexted_augmented_data.jsonl:\n",
      "Successfully loaded 333 valid entries\n",
      "\n",
      "Processing ../data/processed/2-internet_tutorials_cleaned.jsonl:\n",
      "Successfully loaded 260 valid entries\n",
      "\n",
      "Processing ../data/processed/3-late_game_training_cleaned.jsonl:\n",
      "Successfully loaded 8 valid entries\n",
      "\n",
      "Analyzing class distribution...\n",
      "                                     Class  Count\n",
      "0   Offense vs Defense Strategy Techniques     14\n",
      "1             Fundamentals and Soft Skills     14\n",
      "2                  Rake Structure Analysis     14\n",
      "3           Push-Folding Strategy Analysis     14\n",
      "4                   Poker Strategy Lessons     14\n",
      "5                    Poker Humor and Memes     14\n",
      "6               Mixing Strategy Techniques     14\n",
      "7                    Hand History Analysis     14\n",
      "8          Triple-Barrel Bluffing Strategy     14\n",
      "9        Check-Raising Strategy Techniques     14\n",
      "10             Donking Strategy Techniques     14\n",
      "11              Straddle Strategy Analysis     13\n",
      "12                 Monotone Board Strategy     13\n",
      "13       Block-Betting Strategy Techniques     13\n",
      "14              Out-of-Position Strategies     13\n",
      "15      Poker Fundamentals and Soft Skills     13\n",
      "16  Poker Session Review and Hand Analysis     13\n",
      "17                 Flop Shoving Strategies     13\n",
      "18            Poker Variations and Formats     13\n",
      "19               Bluff-Catching Strategies     13\n",
      "20      Squeezing and Setmining Strategies     12\n",
      "21                 GTO Strategy Techniques     12\n",
      "22        Blocker and Unblocker Strategies     11\n",
      "23           Range Construction Techniques     10\n",
      "24                        Stack Strategies      9\n",
      "25                         Equity Analysis      4\n",
      "26             Betting Strategy Techniques      4\n",
      "\n",
      "Saving combined data to ../data/processed/combined_training_data_20241216_031909.jsonl...\n",
      "\n",
      "Total examples in combined dataset: 601\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "jsonl_files = [\n",
    "    '../data/processed/1-contexted_augmented_data.jsonl',\n",
    "    '../data/processed/2-internet_tutorials.jsonl',\n",
    "    '../data/processed/3-late_game_training.jsonl'\n",
    "]\n",
    "\n",
    "# Create training file name with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "combined_file = f'../data/processed/combined_training_data_{timestamp}.jsonl'\n",
    "\n",
    "print(\"Setting up fine-tuning environment...\")\n",
    "\n",
    "# Clean problematic files\n",
    "cleaned_files = [\n",
    "    '../data/processed/1-contexted_augmented_data.jsonl',  # Already clean\n",
    "    clean_and_save_jsonl('../data/processed/2-internet_tutorials.jsonl'),\n",
    "    clean_and_save_jsonl('../data/processed/3-late_game_training.jsonl')\n",
    "]\n",
    "\n",
    "# Load and combine data\n",
    "combined_data = load_and_validate_data(cleaned_files)\n",
    "\n",
    "# Analyze distribution\n",
    "print(\"\\nAnalyzing class distribution...\")\n",
    "distribution = analyze_class_distribution(combined_data)\n",
    "print(distribution)\n",
    "\n",
    "# Save combined data\n",
    "print(f\"\\nSaving combined data to {combined_file}...\")\n",
    "with open(combined_file, 'w', encoding='utf-8') as f:\n",
    "    for entry in combined_data:\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "print(f\"\\nTotal examples in combined dataset: {len(combined_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging with timestamp from previous code\n",
    "os.makedirs('../logs', exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(f'../logs/fine_tuning_{timestamp}.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def validate_training_file(file_path: str) -> bool:\n",
    "    \"\"\"Validate training file before fine-tuning\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = [json.loads(line) for line in f]\n",
    "            total_tokens = sum(len(str(entry)) for entry in data)\n",
    "            logger.info(f\"Training file validation:\")\n",
    "            logger.info(f\"- Number of examples: {len(data)}\")\n",
    "            logger.info(f\"- Approximate total tokens: {total_tokens}\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"File validation failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def setup_fine_tuning(file_path: str, model_name: str = \"gpt-4o-mini-2024-07-18\"):\n",
    "    \"\"\"Setup and start fine-tuning job with enhanced monitoring\"\"\"\n",
    "    try:\n",
    "        # Validate file first\n",
    "        if not validate_training_file(file_path):\n",
    "            raise ValueError(\"Training file validation failed\")\n",
    "\n",
    "        logger.info(f\"Using model: {model_name}\")\n",
    "        logger.info(\"Note: gpt-4o-mini-2024-07-18 pricing:\")\n",
    "        logger.info(\"- Training: $3.000 / 1M training tokens\")\n",
    "        logger.info(\"- Input: $0.300 / 1M input tokens\")\n",
    "        logger.info(\"- Output: $1.200 / 1M output tokens\")\n",
    "\n",
    "        # Create fine-tuning file\n",
    "        logger.info(\"Creating fine-tuning file...\")\n",
    "        with open(file_path, 'rb') as f:\n",
    "            training_file = client.files.create(\n",
    "                file=f,\n",
    "                purpose=\"fine-tune\"\n",
    "            )\n",
    "        logger.info(f\"Training file created with ID: {training_file.id}\")\n",
    "\n",
    "        # Start fine-tuning job with enhanced parameters\n",
    "        logger.info(\"Starting fine-tuning job...\")\n",
    "        job = client.fine_tuning.jobs.create(\n",
    "            training_file=training_file.id,\n",
    "            model=model_name,\n",
    "            hyperparameters={\n",
    "                \"n_epochs\": 3,\n",
    "                \"batch_size\": \"auto\",\n",
    "                \"learning_rate_multiplier\": \"auto\"\n",
    "            }\n",
    "        )\n",
    "        logger.info(f\"Fine-tuning job created with ID: {job.id}\")\n",
    "        return job.id, training_file.id\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during fine-tuning setup: {e}\")\n",
    "        raise\n",
    "\n",
    "def monitor_fine_tuning(job_id: str, check_interval: int = 60):\n",
    "    \"\"\"Enhanced monitoring of fine-tuning job progress\"\"\"\n",
    "    start_time = time.time()\n",
    "    last_token_count = 0\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Get job status\n",
    "            job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "            current_time = time.time()\n",
    "            elapsed_time = current_time - start_time\n",
    "            \n",
    "            # Calculate token processing rate\n",
    "            if job.trained_tokens and last_token_count:\n",
    "                token_rate = (job.trained_tokens - last_token_count) / check_interval\n",
    "                logger.info(f\"Token processing rate: {token_rate:.2f} tokens/second\")\n",
    "            \n",
    "            # Log enhanced status information\n",
    "            logger.info(f\"Status: {job.status}\")\n",
    "            logger.info(f\"Trained tokens: {job.trained_tokens}\")\n",
    "            logger.info(f\"Elapsed time: {elapsed_time/60:.2f} minutes\")\n",
    "            \n",
    "            if job.status in ['succeeded', 'failed']:\n",
    "                if job.status == 'succeeded':\n",
    "                    logger.info(f\"Fine-tuning completed successfully!\")\n",
    "                    logger.info(f\"Model ID: {job.fine_tuned_model}\")\n",
    "                    logger.info(f\"Total training time: {elapsed_time/60:.2f} minutes\")\n",
    "                else:\n",
    "                    logger.error(f\"Fine-tuning failed: {job.error}\")\n",
    "                break\n",
    "            \n",
    "            # Get and log detailed events\n",
    "            events = client.fine_tuning.jobs.list_events(job_id, limit=10)\n",
    "            for event in events.data:\n",
    "                logger.info(f\"Event: {event.message}\")\n",
    "            \n",
    "            # Update token count for rate calculation\n",
    "            last_token_count = job.trained_tokens\n",
    "            time.sleep(check_interval)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error monitoring job: {e}\")\n",
    "            time.sleep(check_interval)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 03:19:57,103 - INFO - === Starting Fine-Tuning Process ===\n",
      "2024-12-16 03:19:57,104 - INFO - Training file: ../data/processed/combined_training_data_20241216_031909.jsonl\n",
      "2024-12-16 03:19:57,115 - INFO - Training file validation:\n",
      "2024-12-16 03:19:57,116 - INFO - - Number of examples: 601\n",
      "2024-12-16 03:19:57,116 - INFO - - Approximate total tokens: 867724\n",
      "2024-12-16 03:19:57,117 - INFO - Using model: gpt-4o-mini-2024-07-18\n",
      "2024-12-16 03:19:57,117 - INFO - Note: gpt-4o-mini-2024-07-18 pricing:\n",
      "2024-12-16 03:19:57,117 - INFO - - Training: $3.000 / 1M training tokens\n",
      "2024-12-16 03:19:57,118 - INFO - - Input: $0.300 / 1M input tokens\n",
      "2024-12-16 03:19:57,118 - INFO - - Output: $1.200 / 1M output tokens\n",
      "2024-12-16 03:19:57,118 - INFO - Creating fine-tuning file...\n",
      "2024-12-16 03:19:58,900 - INFO - HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:19:58,904 - INFO - Training file created with ID: file-GSLJzem7S1UpSXbQBzisVN\n",
      "2024-12-16 03:19:58,905 - INFO - Starting fine-tuning job...\n",
      "2024-12-16 03:20:00,443 - INFO - HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:20:00,459 - INFO - Fine-tuning job created with ID: ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy\n",
      "2024-12-16 03:20:00,460 - INFO - Training file ID: file-GSLJzem7S1UpSXbQBzisVN\n",
      "2024-12-16 03:20:00,460 - INFO - Fine-tuning job ID: ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy\n",
      "2024-12-16 03:20:00,461 - INFO - Starting fine-tuning monitoring...\n",
      "2024-12-16 03:20:00,964 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:20:00,969 - INFO - Status: validating_files\n",
      "2024-12-16 03:20:00,972 - INFO - Trained tokens: None\n",
      "2024-12-16 03:20:00,973 - INFO - Elapsed time: 0.01 minutes\n",
      "2024-12-16 03:20:01,490 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:20:01,492 - INFO - Event: Validating training file: file-GSLJzem7S1UpSXbQBzisVN\n",
      "2024-12-16 03:20:01,492 - INFO - Event: Created fine-tuning job: ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy\n",
      "2024-12-16 03:21:01,964 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:21:01,968 - INFO - Status: validating_files\n",
      "2024-12-16 03:21:01,969 - INFO - Trained tokens: None\n",
      "2024-12-16 03:21:01,969 - INFO - Elapsed time: 1.03 minutes\n",
      "2024-12-16 03:21:02,306 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:21:02,309 - INFO - Event: Validating training file: file-GSLJzem7S1UpSXbQBzisVN\n",
      "2024-12-16 03:21:02,310 - INFO - Event: Created fine-tuning job: ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy\n",
      "2024-12-16 03:22:02,599 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:22:02,603 - INFO - Status: validating_files\n",
      "2024-12-16 03:22:02,604 - INFO - Trained tokens: None\n",
      "2024-12-16 03:22:02,605 - INFO - Elapsed time: 2.04 minutes\n",
      "2024-12-16 03:22:03,124 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:22:03,129 - INFO - Event: Validating training file: file-GSLJzem7S1UpSXbQBzisVN\n",
      "2024-12-16 03:22:03,130 - INFO - Event: Created fine-tuning job: ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy\n",
      "2024-12-16 03:23:03,419 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:23:03,423 - INFO - Status: running\n",
      "2024-12-16 03:23:03,425 - INFO - Trained tokens: None\n",
      "2024-12-16 03:23:03,427 - INFO - Elapsed time: 3.05 minutes\n",
      "2024-12-16 03:23:03,584 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:23:03,588 - INFO - Event: Fine-tuning job started\n",
      "2024-12-16 03:23:03,590 - INFO - Event: Files validated, moving job to queued state\n",
      "2024-12-16 03:23:03,591 - INFO - Event: Validating training file: file-GSLJzem7S1UpSXbQBzisVN\n",
      "2024-12-16 03:23:03,592 - INFO - Event: Created fine-tuning job: ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy\n",
      "2024-12-16 03:24:03,909 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:24:03,912 - INFO - Status: running\n",
      "2024-12-16 03:24:03,914 - INFO - Trained tokens: None\n",
      "2024-12-16 03:24:03,915 - INFO - Elapsed time: 4.06 minutes\n",
      "2024-12-16 03:24:04,324 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:24:04,332 - INFO - Event: Fine-tuning job started\n",
      "2024-12-16 03:24:04,333 - INFO - Event: Files validated, moving job to queued state\n",
      "2024-12-16 03:24:04,334 - INFO - Event: Validating training file: file-GSLJzem7S1UpSXbQBzisVN\n",
      "2024-12-16 03:24:04,334 - INFO - Event: Created fine-tuning job: ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy\n",
      "2024-12-16 03:25:05,185 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:25:05,190 - INFO - Status: running\n",
      "2024-12-16 03:25:05,191 - INFO - Trained tokens: None\n",
      "2024-12-16 03:25:05,193 - INFO - Elapsed time: 5.08 minutes\n",
      "2024-12-16 03:25:05,361 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:25:05,363 - INFO - Event: Step 1/1803: training loss=2.58\n",
      "2024-12-16 03:25:05,364 - INFO - Event: Fine-tuning job started\n",
      "2024-12-16 03:25:05,364 - INFO - Event: Files validated, moving job to queued state\n",
      "2024-12-16 03:25:05,365 - INFO - Event: Validating training file: file-GSLJzem7S1UpSXbQBzisVN\n",
      "2024-12-16 03:25:05,366 - INFO - Event: Created fine-tuning job: ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy\n",
      "2024-12-16 03:26:05,612 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:26:05,615 - INFO - Status: running\n",
      "2024-12-16 03:26:05,616 - INFO - Trained tokens: None\n",
      "2024-12-16 03:26:05,617 - INFO - Elapsed time: 6.09 minutes\n",
      "2024-12-16 03:26:05,858 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:26:05,861 - INFO - Event: Step 51/1803: training loss=1.75\n",
      "2024-12-16 03:26:05,862 - INFO - Event: Step 50/1803: training loss=1.06\n",
      "2024-12-16 03:26:05,863 - INFO - Event: Step 49/1803: training loss=0.81\n",
      "2024-12-16 03:26:05,863 - INFO - Event: Step 48/1803: training loss=1.50\n",
      "2024-12-16 03:26:05,864 - INFO - Event: Step 47/1803: training loss=1.51\n",
      "2024-12-16 03:26:05,865 - INFO - Event: Step 46/1803: training loss=1.33\n",
      "2024-12-16 03:26:05,865 - INFO - Event: Step 45/1803: training loss=1.31\n",
      "2024-12-16 03:26:05,866 - INFO - Event: Step 44/1803: training loss=2.46\n",
      "2024-12-16 03:26:05,866 - INFO - Event: Step 43/1803: training loss=2.04\n",
      "2024-12-16 03:26:05,867 - INFO - Event: Step 42/1803: training loss=0.79\n",
      "2024-12-16 03:27:06,291 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:27:06,295 - INFO - Status: running\n",
      "2024-12-16 03:27:06,296 - INFO - Trained tokens: None\n",
      "2024-12-16 03:27:06,297 - INFO - Elapsed time: 7.10 minutes\n",
      "2024-12-16 03:27:06,512 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:27:06,514 - INFO - Event: Step 103/1803: training loss=1.21\n",
      "2024-12-16 03:27:06,515 - INFO - Event: Step 102/1803: training loss=1.04\n",
      "2024-12-16 03:27:06,516 - INFO - Event: Step 101/1803: training loss=1.19\n",
      "2024-12-16 03:27:06,516 - INFO - Event: Step 100/1803: training loss=1.33\n",
      "2024-12-16 03:27:06,517 - INFO - Event: Step 99/1803: training loss=1.31\n",
      "2024-12-16 03:27:06,517 - INFO - Event: Step 98/1803: training loss=0.89\n",
      "2024-12-16 03:27:06,518 - INFO - Event: Step 97/1803: training loss=1.42\n",
      "2024-12-16 03:27:06,519 - INFO - Event: Step 96/1803: training loss=1.13\n",
      "2024-12-16 03:27:06,519 - INFO - Event: Step 95/1803: training loss=1.01\n",
      "2024-12-16 03:27:06,519 - INFO - Event: Step 94/1803: training loss=1.22\n",
      "2024-12-16 03:28:07,034 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:28:07,039 - INFO - Status: running\n",
      "2024-12-16 03:28:07,040 - INFO - Trained tokens: None\n",
      "2024-12-16 03:28:07,042 - INFO - Elapsed time: 8.11 minutes\n",
      "2024-12-16 03:28:07,235 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:28:07,242 - INFO - Event: Step 154/1803: training loss=1.05\n",
      "2024-12-16 03:28:07,243 - INFO - Event: Step 153/1803: training loss=1.57\n",
      "2024-12-16 03:28:07,244 - INFO - Event: Step 152/1803: training loss=0.54\n",
      "2024-12-16 03:28:07,245 - INFO - Event: Step 151/1803: training loss=0.52\n",
      "2024-12-16 03:28:07,246 - INFO - Event: Step 150/1803: training loss=1.18\n",
      "2024-12-16 03:28:07,248 - INFO - Event: Step 149/1803: training loss=1.14\n",
      "2024-12-16 03:28:07,248 - INFO - Event: Step 148/1803: training loss=1.22\n",
      "2024-12-16 03:28:07,249 - INFO - Event: Step 147/1803: training loss=1.29\n",
      "2024-12-16 03:28:07,250 - INFO - Event: Step 146/1803: training loss=1.18\n",
      "2024-12-16 03:28:07,250 - INFO - Event: Step 145/1803: training loss=1.16\n",
      "2024-12-16 03:29:07,486 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:29:07,490 - INFO - Status: running\n",
      "2024-12-16 03:29:07,491 - INFO - Trained tokens: None\n",
      "2024-12-16 03:29:07,497 - INFO - Elapsed time: 9.12 minutes\n",
      "2024-12-16 03:29:07,704 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:29:07,706 - INFO - Event: Step 203/1803: training loss=1.16\n",
      "2024-12-16 03:29:07,707 - INFO - Event: Step 202/1803: training loss=0.88\n",
      "2024-12-16 03:29:07,708 - INFO - Event: Step 201/1803: training loss=1.30\n",
      "2024-12-16 03:29:07,708 - INFO - Event: Step 200/1803: training loss=1.09\n",
      "2024-12-16 03:29:07,709 - INFO - Event: Step 199/1803: training loss=0.82\n",
      "2024-12-16 03:29:07,709 - INFO - Event: Step 198/1803: training loss=0.79\n",
      "2024-12-16 03:29:07,710 - INFO - Event: Step 197/1803: training loss=1.26\n",
      "2024-12-16 03:29:07,710 - INFO - Event: Step 196/1803: training loss=1.08\n",
      "2024-12-16 03:29:07,711 - INFO - Event: Step 195/1803: training loss=0.98\n",
      "2024-12-16 03:29:07,711 - INFO - Event: Step 194/1803: training loss=0.67\n",
      "2024-12-16 03:30:07,957 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:30:07,962 - INFO - Status: running\n",
      "2024-12-16 03:30:07,963 - INFO - Trained tokens: None\n",
      "2024-12-16 03:30:07,964 - INFO - Elapsed time: 10.13 minutes\n",
      "2024-12-16 03:30:08,152 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:30:08,156 - INFO - Event: Step 261/1803: training loss=0.70\n",
      "2024-12-16 03:30:08,157 - INFO - Event: Step 260/1803: training loss=1.11\n",
      "2024-12-16 03:30:08,158 - INFO - Event: Step 259/1803: training loss=0.53\n",
      "2024-12-16 03:30:08,159 - INFO - Event: Step 258/1803: training loss=0.99\n",
      "2024-12-16 03:30:08,159 - INFO - Event: Step 257/1803: training loss=0.47\n",
      "2024-12-16 03:30:08,160 - INFO - Event: Step 256/1803: training loss=2.08\n",
      "2024-12-16 03:30:08,160 - INFO - Event: Step 255/1803: training loss=1.42\n",
      "2024-12-16 03:30:08,161 - INFO - Event: Step 254/1803: training loss=1.26\n",
      "2024-12-16 03:30:08,162 - INFO - Event: Step 253/1803: training loss=1.49\n",
      "2024-12-16 03:30:08,162 - INFO - Event: Step 252/1803: training loss=0.98\n",
      "2024-12-16 03:31:08,511 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:31:08,516 - INFO - Status: running\n",
      "2024-12-16 03:31:08,517 - INFO - Trained tokens: None\n",
      "2024-12-16 03:31:08,518 - INFO - Elapsed time: 11.13 minutes\n",
      "2024-12-16 03:31:08,738 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:31:08,741 - INFO - Event: Step 313/1803: training loss=1.06\n",
      "2024-12-16 03:31:08,741 - INFO - Event: Step 312/1803: training loss=1.02\n",
      "2024-12-16 03:31:08,742 - INFO - Event: Step 311/1803: training loss=1.24\n",
      "2024-12-16 03:31:08,743 - INFO - Event: Step 310/1803: training loss=0.87\n",
      "2024-12-16 03:31:08,743 - INFO - Event: Step 309/1803: training loss=1.13\n",
      "2024-12-16 03:31:08,744 - INFO - Event: Step 308/1803: training loss=1.17\n",
      "2024-12-16 03:31:08,744 - INFO - Event: Step 307/1803: training loss=1.13\n",
      "2024-12-16 03:31:08,745 - INFO - Event: Step 306/1803: training loss=1.06\n",
      "2024-12-16 03:31:08,745 - INFO - Event: Step 305/1803: training loss=1.40\n",
      "2024-12-16 03:31:08,746 - INFO - Event: Step 304/1803: training loss=0.78\n",
      "2024-12-16 03:32:08,959 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:32:08,962 - INFO - Status: running\n",
      "2024-12-16 03:32:08,962 - INFO - Trained tokens: None\n",
      "2024-12-16 03:32:08,963 - INFO - Elapsed time: 12.14 minutes\n",
      "2024-12-16 03:32:09,128 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:32:09,133 - INFO - Event: Step 366/1803: training loss=1.06\n",
      "2024-12-16 03:32:09,134 - INFO - Event: Step 365/1803: training loss=1.18\n",
      "2024-12-16 03:32:09,135 - INFO - Event: Step 364/1803: training loss=0.97\n",
      "2024-12-16 03:32:09,136 - INFO - Event: Step 363/1803: training loss=0.41\n",
      "2024-12-16 03:32:09,137 - INFO - Event: Step 362/1803: training loss=1.61\n",
      "2024-12-16 03:32:09,137 - INFO - Event: Step 361/1803: training loss=1.02\n",
      "2024-12-16 03:32:09,138 - INFO - Event: Step 360/1803: training loss=0.86\n",
      "2024-12-16 03:32:09,139 - INFO - Event: Step 359/1803: training loss=0.95\n",
      "2024-12-16 03:32:09,139 - INFO - Event: Step 358/1803: training loss=0.73\n",
      "2024-12-16 03:32:09,140 - INFO - Event: Step 357/1803: training loss=0.87\n",
      "2024-12-16 03:33:09,499 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:33:09,503 - INFO - Status: running\n",
      "2024-12-16 03:33:09,506 - INFO - Trained tokens: None\n",
      "2024-12-16 03:33:09,507 - INFO - Elapsed time: 13.15 minutes\n",
      "2024-12-16 03:33:09,662 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:33:09,664 - INFO - Event: Step 427/1803: training loss=0.44\n",
      "2024-12-16 03:33:09,665 - INFO - Event: Step 426/1803: training loss=1.31\n",
      "2024-12-16 03:33:09,665 - INFO - Event: Step 425/1803: training loss=1.37\n",
      "2024-12-16 03:33:09,665 - INFO - Event: Step 424/1803: training loss=2.17\n",
      "2024-12-16 03:33:09,666 - INFO - Event: Step 423/1803: training loss=1.25\n",
      "2024-12-16 03:33:09,666 - INFO - Event: Step 422/1803: training loss=0.93\n",
      "2024-12-16 03:33:09,667 - INFO - Event: Step 421/1803: training loss=0.53\n",
      "2024-12-16 03:33:09,667 - INFO - Event: Step 420/1803: training loss=1.07\n",
      "2024-12-16 03:33:09,667 - INFO - Event: Step 419/1803: training loss=1.37\n",
      "2024-12-16 03:33:09,668 - INFO - Event: Step 418/1803: training loss=1.18\n",
      "2024-12-16 03:34:10,919 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:34:10,924 - INFO - Status: running\n",
      "2024-12-16 03:34:10,925 - INFO - Trained tokens: None\n",
      "2024-12-16 03:34:10,927 - INFO - Elapsed time: 14.17 minutes\n",
      "2024-12-16 03:34:11,175 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:34:11,177 - INFO - Event: Step 477/1803: training loss=1.24\n",
      "2024-12-16 03:34:11,178 - INFO - Event: Step 476/1803: training loss=0.75\n",
      "2024-12-16 03:34:11,178 - INFO - Event: Step 475/1803: training loss=0.99\n",
      "2024-12-16 03:34:11,179 - INFO - Event: Step 474/1803: training loss=1.04\n",
      "2024-12-16 03:34:11,180 - INFO - Event: Step 473/1803: training loss=1.39\n",
      "2024-12-16 03:34:11,180 - INFO - Event: Step 472/1803: training loss=1.01\n",
      "2024-12-16 03:34:11,181 - INFO - Event: Step 471/1803: training loss=0.97\n",
      "2024-12-16 03:34:11,181 - INFO - Event: Step 470/1803: training loss=0.08\n",
      "2024-12-16 03:34:11,182 - INFO - Event: Step 469/1803: training loss=0.87\n",
      "2024-12-16 03:34:11,182 - INFO - Event: Step 468/1803: training loss=1.05\n",
      "2024-12-16 03:35:11,409 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:35:11,412 - INFO - Status: running\n",
      "2024-12-16 03:35:11,413 - INFO - Trained tokens: None\n",
      "2024-12-16 03:35:11,414 - INFO - Elapsed time: 15.18 minutes\n",
      "2024-12-16 03:35:11,616 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:35:11,618 - INFO - Event: Step 534/1803: training loss=1.07\n",
      "2024-12-16 03:35:11,619 - INFO - Event: Step 533/1803: training loss=1.33\n",
      "2024-12-16 03:35:11,619 - INFO - Event: Step 532/1803: training loss=0.88\n",
      "2024-12-16 03:35:11,620 - INFO - Event: Step 531/1803: training loss=1.14\n",
      "2024-12-16 03:35:11,620 - INFO - Event: Step 530/1803: training loss=1.16\n",
      "2024-12-16 03:35:11,621 - INFO - Event: Step 529/1803: training loss=1.06\n",
      "2024-12-16 03:35:11,622 - INFO - Event: Step 528/1803: training loss=1.10\n",
      "2024-12-16 03:35:11,622 - INFO - Event: Step 527/1803: training loss=1.05\n",
      "2024-12-16 03:35:11,623 - INFO - Event: Step 526/1803: training loss=0.71\n",
      "2024-12-16 03:35:11,623 - INFO - Event: Step 525/1803: training loss=1.18\n",
      "2024-12-16 03:36:11,879 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:36:11,884 - INFO - Status: running\n",
      "2024-12-16 03:36:11,886 - INFO - Trained tokens: None\n",
      "2024-12-16 03:36:11,887 - INFO - Elapsed time: 16.19 minutes\n",
      "2024-12-16 03:36:12,077 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:36:12,082 - INFO - Event: Step 587/1803: training loss=1.16\n",
      "2024-12-16 03:36:12,083 - INFO - Event: Step 586/1803: training loss=0.88\n",
      "2024-12-16 03:36:12,084 - INFO - Event: Step 585/1803: training loss=1.16\n",
      "2024-12-16 03:36:12,085 - INFO - Event: Step 584/1803: training loss=1.08\n",
      "2024-12-16 03:36:12,085 - INFO - Event: Step 583/1803: training loss=0.91\n",
      "2024-12-16 03:36:12,086 - INFO - Event: Step 582/1803: training loss=0.31\n",
      "2024-12-16 03:36:12,087 - INFO - Event: Step 581/1803: training loss=1.21\n",
      "2024-12-16 03:36:12,087 - INFO - Event: Step 580/1803: training loss=0.24\n",
      "2024-12-16 03:36:12,087 - INFO - Event: Step 579/1803: training loss=1.00\n",
      "2024-12-16 03:36:12,088 - INFO - Event: Step 578/1803: training loss=0.90\n",
      "2024-12-16 03:37:12,320 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:37:12,325 - INFO - Status: running\n",
      "2024-12-16 03:37:12,330 - INFO - Trained tokens: None\n",
      "2024-12-16 03:37:12,330 - INFO - Elapsed time: 17.20 minutes\n",
      "2024-12-16 03:37:12,508 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:37:12,513 - INFO - Event: Step 606/1803: training loss=1.05\n",
      "2024-12-16 03:37:12,515 - INFO - Event: Step 605/1803: training loss=0.67\n",
      "2024-12-16 03:37:12,516 - INFO - Event: Step 604/1803: training loss=0.76\n",
      "2024-12-16 03:37:12,517 - INFO - Event: Step 603/1803: training loss=0.58\n",
      "2024-12-16 03:37:12,519 - INFO - Event: Step 602/1803: training loss=1.28\n",
      "2024-12-16 03:37:12,519 - INFO - Event: Step 601/1803: training loss=1.46\n",
      "2024-12-16 03:37:12,520 - INFO - Event: Step 600/1803: training loss=1.00\n",
      "2024-12-16 03:37:12,520 - INFO - Event: Step 599/1803: training loss=1.22\n",
      "2024-12-16 03:37:12,521 - INFO - Event: Step 598/1803: training loss=1.22\n",
      "2024-12-16 03:37:12,522 - INFO - Event: Step 597/1803: training loss=0.18\n",
      "2024-12-16 03:38:12,794 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:38:12,799 - INFO - Status: running\n",
      "2024-12-16 03:38:12,799 - INFO - Trained tokens: None\n",
      "2024-12-16 03:38:12,800 - INFO - Elapsed time: 18.21 minutes\n",
      "2024-12-16 03:38:13,011 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:38:13,013 - INFO - Event: Step 655/1803: training loss=1.18\n",
      "2024-12-16 03:38:13,014 - INFO - Event: Step 654/1803: training loss=0.82\n",
      "2024-12-16 03:38:13,014 - INFO - Event: Step 653/1803: training loss=0.92\n",
      "2024-12-16 03:38:13,015 - INFO - Event: Step 652/1803: training loss=1.16\n",
      "2024-12-16 03:38:13,016 - INFO - Event: Step 651/1803: training loss=0.85\n",
      "2024-12-16 03:38:13,017 - INFO - Event: Step 650/1803: training loss=1.64\n",
      "2024-12-16 03:38:13,017 - INFO - Event: Step 649/1803: training loss=1.15\n",
      "2024-12-16 03:38:13,017 - INFO - Event: Step 648/1803: training loss=0.91\n",
      "2024-12-16 03:38:13,018 - INFO - Event: Step 647/1803: training loss=0.92\n",
      "2024-12-16 03:38:13,018 - INFO - Event: Step 646/1803: training loss=1.14\n",
      "2024-12-16 03:39:13,268 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:39:13,272 - INFO - Status: running\n",
      "2024-12-16 03:39:13,275 - INFO - Trained tokens: None\n",
      "2024-12-16 03:39:13,276 - INFO - Elapsed time: 19.21 minutes\n",
      "2024-12-16 03:39:13,604 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:39:13,608 - INFO - Event: Step 717/1803: training loss=0.79\n",
      "2024-12-16 03:39:13,609 - INFO - Event: Step 716/1803: training loss=0.94\n",
      "2024-12-16 03:39:13,610 - INFO - Event: Step 715/1803: training loss=0.99\n",
      "2024-12-16 03:39:13,611 - INFO - Event: Step 714/1803: training loss=0.41\n",
      "2024-12-16 03:39:13,611 - INFO - Event: Step 713/1803: training loss=0.85\n",
      "2024-12-16 03:39:13,612 - INFO - Event: Step 712/1803: training loss=0.17\n",
      "2024-12-16 03:39:13,613 - INFO - Event: Step 711/1803: training loss=0.88\n",
      "2024-12-16 03:39:13,613 - INFO - Event: Step 710/1803: training loss=0.77\n",
      "2024-12-16 03:39:13,614 - INFO - Event: Step 709/1803: training loss=1.11\n",
      "2024-12-16 03:39:13,614 - INFO - Event: Step 708/1803: training loss=0.14\n",
      "2024-12-16 03:40:13,868 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:40:13,870 - INFO - Status: running\n",
      "2024-12-16 03:40:13,870 - INFO - Trained tokens: None\n",
      "2024-12-16 03:40:13,871 - INFO - Elapsed time: 20.22 minutes\n",
      "2024-12-16 03:40:14,050 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:40:14,053 - INFO - Event: Step 764/1803: training loss=0.03\n",
      "2024-12-16 03:40:14,054 - INFO - Event: Step 763/1803: training loss=0.64\n",
      "2024-12-16 03:40:14,054 - INFO - Event: Step 762/1803: training loss=1.02\n",
      "2024-12-16 03:40:14,055 - INFO - Event: Step 761/1803: training loss=0.91\n",
      "2024-12-16 03:40:14,055 - INFO - Event: Step 760/1803: training loss=0.41\n",
      "2024-12-16 03:40:14,056 - INFO - Event: Step 759/1803: training loss=0.79\n",
      "2024-12-16 03:40:14,056 - INFO - Event: Step 758/1803: training loss=0.98\n",
      "2024-12-16 03:40:14,057 - INFO - Event: Step 757/1803: training loss=0.32\n",
      "2024-12-16 03:40:14,057 - INFO - Event: Step 756/1803: training loss=0.76\n",
      "2024-12-16 03:40:14,058 - INFO - Event: Step 755/1803: training loss=0.72\n",
      "2024-12-16 03:41:14,288 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:41:14,291 - INFO - Status: running\n",
      "2024-12-16 03:41:14,291 - INFO - Trained tokens: None\n",
      "2024-12-16 03:41:14,292 - INFO - Elapsed time: 21.23 minutes\n",
      "2024-12-16 03:41:14,507 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:41:14,514 - INFO - Event: Step 823/1803: training loss=0.69\n",
      "2024-12-16 03:41:14,516 - INFO - Event: Step 822/1803: training loss=0.77\n",
      "2024-12-16 03:41:14,516 - INFO - Event: Step 821/1803: training loss=0.83\n",
      "2024-12-16 03:41:14,519 - INFO - Event: Step 820/1803: training loss=0.86\n",
      "2024-12-16 03:41:14,520 - INFO - Event: Step 819/1803: training loss=0.98\n",
      "2024-12-16 03:41:14,520 - INFO - Event: Step 818/1803: training loss=0.37\n",
      "2024-12-16 03:41:14,521 - INFO - Event: Step 817/1803: training loss=0.27\n",
      "2024-12-16 03:41:14,522 - INFO - Event: Step 816/1803: training loss=0.85\n",
      "2024-12-16 03:41:14,523 - INFO - Event: Step 815/1803: training loss=0.99\n",
      "2024-12-16 03:41:14,523 - INFO - Event: Step 814/1803: training loss=0.81\n",
      "2024-12-16 03:42:14,769 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:42:14,773 - INFO - Status: running\n",
      "2024-12-16 03:42:14,774 - INFO - Trained tokens: None\n",
      "2024-12-16 03:42:14,776 - INFO - Elapsed time: 22.24 minutes\n",
      "2024-12-16 03:42:15,251 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:42:15,256 - INFO - Event: Step 876/1803: training loss=0.06\n",
      "2024-12-16 03:42:15,257 - INFO - Event: Step 875/1803: training loss=0.88\n",
      "2024-12-16 03:42:15,258 - INFO - Event: Step 874/1803: training loss=0.17\n",
      "2024-12-16 03:42:15,258 - INFO - Event: Step 873/1803: training loss=0.91\n",
      "2024-12-16 03:42:15,259 - INFO - Event: Step 872/1803: training loss=0.48\n",
      "2024-12-16 03:42:15,259 - INFO - Event: Step 871/1803: training loss=0.85\n",
      "2024-12-16 03:42:15,260 - INFO - Event: Step 870/1803: training loss=1.34\n",
      "2024-12-16 03:42:15,261 - INFO - Event: Step 869/1803: training loss=0.01\n",
      "2024-12-16 03:42:15,261 - INFO - Event: Step 868/1803: training loss=0.90\n",
      "2024-12-16 03:42:15,262 - INFO - Event: Step 867/1803: training loss=0.99\n",
      "2024-12-16 03:43:15,516 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:43:15,520 - INFO - Status: running\n",
      "2024-12-16 03:43:15,523 - INFO - Trained tokens: None\n",
      "2024-12-16 03:43:15,524 - INFO - Elapsed time: 23.25 minutes\n",
      "2024-12-16 03:43:15,742 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:43:15,749 - INFO - Event: Step 923/1803: training loss=0.92\n",
      "2024-12-16 03:43:15,751 - INFO - Event: Step 922/1803: training loss=0.98\n",
      "2024-12-16 03:43:15,752 - INFO - Event: Step 921/1803: training loss=0.94\n",
      "2024-12-16 03:43:15,752 - INFO - Event: Step 920/1803: training loss=0.88\n",
      "2024-12-16 03:43:15,754 - INFO - Event: Step 919/1803: training loss=0.07\n",
      "2024-12-16 03:43:15,755 - INFO - Event: Step 918/1803: training loss=1.13\n",
      "2024-12-16 03:43:15,755 - INFO - Event: Step 917/1803: training loss=1.09\n",
      "2024-12-16 03:43:15,756 - INFO - Event: Step 916/1803: training loss=0.98\n",
      "2024-12-16 03:43:15,756 - INFO - Event: Step 915/1803: training loss=0.87\n",
      "2024-12-16 03:43:15,757 - INFO - Event: Step 914/1803: training loss=1.03\n",
      "2024-12-16 03:44:15,990 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:44:15,994 - INFO - Status: running\n",
      "2024-12-16 03:44:15,996 - INFO - Trained tokens: None\n",
      "2024-12-16 03:44:15,997 - INFO - Elapsed time: 24.26 minutes\n",
      "2024-12-16 03:44:16,213 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:44:16,216 - INFO - Event: Step 980/1803: training loss=0.13\n",
      "2024-12-16 03:44:16,217 - INFO - Event: Step 979/1803: training loss=0.97\n",
      "2024-12-16 03:44:16,217 - INFO - Event: Step 978/1803: training loss=0.13\n",
      "2024-12-16 03:44:16,218 - INFO - Event: Step 977/1803: training loss=0.89\n",
      "2024-12-16 03:44:16,218 - INFO - Event: Step 976/1803: training loss=0.89\n",
      "2024-12-16 03:44:16,219 - INFO - Event: Step 975/1803: training loss=0.38\n",
      "2024-12-16 03:44:16,219 - INFO - Event: Step 974/1803: training loss=0.95\n",
      "2024-12-16 03:44:16,220 - INFO - Event: Step 973/1803: training loss=0.52\n",
      "2024-12-16 03:44:16,220 - INFO - Event: Step 972/1803: training loss=0.87\n",
      "2024-12-16 03:44:16,221 - INFO - Event: Step 971/1803: training loss=0.62\n",
      "2024-12-16 03:45:16,497 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:45:16,502 - INFO - Status: running\n",
      "2024-12-16 03:45:16,504 - INFO - Trained tokens: None\n",
      "2024-12-16 03:45:16,505 - INFO - Elapsed time: 25.27 minutes\n",
      "2024-12-16 03:45:16,696 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:45:16,701 - INFO - Event: Step 1038/1803: training loss=0.34\n",
      "2024-12-16 03:45:16,702 - INFO - Event: Step 1037/1803: training loss=0.85\n",
      "2024-12-16 03:45:16,702 - INFO - Event: Step 1036/1803: training loss=0.85\n",
      "2024-12-16 03:45:16,703 - INFO - Event: Step 1035/1803: training loss=1.39\n",
      "2024-12-16 03:45:16,704 - INFO - Event: Step 1034/1803: training loss=1.08\n",
      "2024-12-16 03:45:16,704 - INFO - Event: Step 1033/1803: training loss=1.23\n",
      "2024-12-16 03:45:16,705 - INFO - Event: Step 1032/1803: training loss=1.02\n",
      "2024-12-16 03:45:16,705 - INFO - Event: Step 1031/1803: training loss=0.30\n",
      "2024-12-16 03:45:16,706 - INFO - Event: Step 1030/1803: training loss=0.61\n",
      "2024-12-16 03:45:16,706 - INFO - Event: Step 1029/1803: training loss=1.15\n",
      "2024-12-16 03:46:16,929 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:46:16,934 - INFO - Status: running\n",
      "2024-12-16 03:46:16,936 - INFO - Trained tokens: None\n",
      "2024-12-16 03:46:16,937 - INFO - Elapsed time: 26.27 minutes\n",
      "2024-12-16 03:46:17,108 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:46:17,111 - INFO - Event: Step 1092/1803: training loss=1.05\n",
      "2024-12-16 03:46:17,111 - INFO - Event: Step 1091/1803: training loss=0.02\n",
      "2024-12-16 03:46:17,112 - INFO - Event: Step 1090/1803: training loss=0.86\n",
      "2024-12-16 03:46:17,112 - INFO - Event: Step 1089/1803: training loss=0.70\n",
      "2024-12-16 03:46:17,113 - INFO - Event: Step 1088/1803: training loss=0.60\n",
      "2024-12-16 03:46:17,113 - INFO - Event: Step 1087/1803: training loss=0.59\n",
      "2024-12-16 03:46:17,114 - INFO - Event: Step 1086/1803: training loss=0.54\n",
      "2024-12-16 03:46:17,115 - INFO - Event: Step 1085/1803: training loss=0.08\n",
      "2024-12-16 03:46:17,115 - INFO - Event: Step 1084/1803: training loss=0.99\n",
      "2024-12-16 03:46:17,116 - INFO - Event: Step 1083/1803: training loss=1.04\n",
      "2024-12-16 03:47:17,366 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:47:17,368 - INFO - Status: running\n",
      "2024-12-16 03:47:17,369 - INFO - Trained tokens: None\n",
      "2024-12-16 03:47:17,370 - INFO - Elapsed time: 27.28 minutes\n",
      "2024-12-16 03:47:17,580 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:47:17,583 - INFO - Event: Step 1144/1803: training loss=0.72\n",
      "2024-12-16 03:47:17,584 - INFO - Event: Step 1143/1803: training loss=0.34\n",
      "2024-12-16 03:47:17,585 - INFO - Event: Step 1142/1803: training loss=0.84\n",
      "2024-12-16 03:47:17,586 - INFO - Event: Step 1141/1803: training loss=0.90\n",
      "2024-12-16 03:47:17,586 - INFO - Event: Step 1140/1803: training loss=1.13\n",
      "2024-12-16 03:47:17,587 - INFO - Event: Step 1139/1803: training loss=0.99\n",
      "2024-12-16 03:47:17,588 - INFO - Event: Step 1138/1803: training loss=0.73\n",
      "2024-12-16 03:47:17,588 - INFO - Event: Step 1137/1803: training loss=0.12\n",
      "2024-12-16 03:47:17,589 - INFO - Event: Step 1136/1803: training loss=0.70\n",
      "2024-12-16 03:47:17,589 - INFO - Event: Step 1135/1803: training loss=0.83\n",
      "2024-12-16 03:48:17,849 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:48:17,854 - INFO - Status: running\n",
      "2024-12-16 03:48:17,855 - INFO - Trained tokens: None\n",
      "2024-12-16 03:48:17,857 - INFO - Elapsed time: 28.29 minutes\n",
      "2024-12-16 03:48:18,096 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:48:18,101 - INFO - Event: Step 1193/1803: training loss=0.84\n",
      "2024-12-16 03:48:18,102 - INFO - Event: Step 1192/1803: training loss=0.01\n",
      "2024-12-16 03:48:18,103 - INFO - Event: Step 1191/1803: training loss=0.86\n",
      "2024-12-16 03:48:18,103 - INFO - Event: Step 1190/1803: training loss=0.00\n",
      "2024-12-16 03:48:18,104 - INFO - Event: Step 1189/1803: training loss=1.03\n",
      "2024-12-16 03:48:18,105 - INFO - Event: Step 1188/1803: training loss=1.13\n",
      "2024-12-16 03:48:18,105 - INFO - Event: Step 1187/1803: training loss=0.83\n",
      "2024-12-16 03:48:18,106 - INFO - Event: Step 1186/1803: training loss=1.64\n",
      "2024-12-16 03:48:18,106 - INFO - Event: Step 1185/1803: training loss=1.17\n",
      "2024-12-16 03:48:18,107 - INFO - Event: Step 1184/1803: training loss=0.26\n",
      "2024-12-16 03:49:18,343 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:49:18,345 - INFO - Status: running\n",
      "2024-12-16 03:49:18,345 - INFO - Trained tokens: None\n",
      "2024-12-16 03:49:18,345 - INFO - Elapsed time: 29.30 minutes\n",
      "2024-12-16 03:49:18,529 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:49:18,538 - INFO - Event: Step 1218/1803: training loss=0.79\n",
      "2024-12-16 03:49:18,539 - INFO - Event: Step 1217/1803: training loss=0.19\n",
      "2024-12-16 03:49:18,540 - INFO - Event: Step 1216/1803: training loss=1.23\n",
      "2024-12-16 03:49:18,540 - INFO - Event: Step 1215/1803: training loss=0.78\n",
      "2024-12-16 03:49:18,541 - INFO - Event: Step 1214/1803: training loss=0.78\n",
      "2024-12-16 03:49:18,542 - INFO - Event: Step 1213/1803: training loss=0.44\n",
      "2024-12-16 03:49:18,543 - INFO - Event: Step 1212/1803: training loss=0.62\n",
      "2024-12-16 03:49:18,544 - INFO - Event: Step 1211/1803: training loss=0.63\n",
      "2024-12-16 03:49:18,544 - INFO - Event: Step 1210/1803: training loss=0.85\n",
      "2024-12-16 03:49:18,545 - INFO - Event: Step 1209/1803: training loss=0.58\n",
      "2024-12-16 03:50:18,903 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:50:18,906 - INFO - Status: running\n",
      "2024-12-16 03:50:18,907 - INFO - Trained tokens: None\n",
      "2024-12-16 03:50:18,907 - INFO - Elapsed time: 30.31 minutes\n",
      "2024-12-16 03:50:19,131 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:50:19,136 - INFO - Event: Step 1270/1803: training loss=0.01\n",
      "2024-12-16 03:50:19,136 - INFO - Event: Step 1269/1803: training loss=0.74\n",
      "2024-12-16 03:50:19,137 - INFO - Event: Step 1268/1803: training loss=0.64\n",
      "2024-12-16 03:50:19,138 - INFO - Event: Step 1267/1803: training loss=0.95\n",
      "2024-12-16 03:50:19,138 - INFO - Event: Step 1266/1803: training loss=0.79\n",
      "2024-12-16 03:50:19,139 - INFO - Event: Step 1265/1803: training loss=0.33\n",
      "2024-12-16 03:50:19,140 - INFO - Event: Step 1264/1803: training loss=0.69\n",
      "2024-12-16 03:50:19,140 - INFO - Event: Step 1263/1803: training loss=0.80\n",
      "2024-12-16 03:50:19,140 - INFO - Event: Step 1262/1803: training loss=0.01\n",
      "2024-12-16 03:50:19,141 - INFO - Event: Step 1261/1803: training loss=0.58\n",
      "2024-12-16 03:51:19,375 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:51:19,380 - INFO - Status: running\n",
      "2024-12-16 03:51:19,382 - INFO - Trained tokens: None\n",
      "2024-12-16 03:51:19,383 - INFO - Elapsed time: 31.32 minutes\n",
      "2024-12-16 03:51:19,547 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:51:19,549 - INFO - Event: Step 1329/1803: training loss=1.03\n",
      "2024-12-16 03:51:19,550 - INFO - Event: Step 1328/1803: training loss=0.88\n",
      "2024-12-16 03:51:19,550 - INFO - Event: Step 1327/1803: training loss=0.71\n",
      "2024-12-16 03:51:19,551 - INFO - Event: Step 1326/1803: training loss=0.81\n",
      "2024-12-16 03:51:19,551 - INFO - Event: Step 1325/1803: training loss=0.90\n",
      "2024-12-16 03:51:19,552 - INFO - Event: Step 1324/1803: training loss=0.67\n",
      "2024-12-16 03:51:19,552 - INFO - Event: Step 1323/1803: training loss=0.19\n",
      "2024-12-16 03:51:19,553 - INFO - Event: Step 1322/1803: training loss=0.59\n",
      "2024-12-16 03:51:19,553 - INFO - Event: Step 1321/1803: training loss=0.01\n",
      "2024-12-16 03:51:19,554 - INFO - Event: Step 1320/1803: training loss=0.00\n",
      "2024-12-16 03:52:19,777 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:52:19,782 - INFO - Status: running\n",
      "2024-12-16 03:52:19,783 - INFO - Trained tokens: None\n",
      "2024-12-16 03:52:19,785 - INFO - Elapsed time: 32.32 minutes\n",
      "2024-12-16 03:52:19,945 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:52:19,949 - INFO - Event: Step 1381/1803: training loss=0.71\n",
      "2024-12-16 03:52:19,950 - INFO - Event: Step 1380/1803: training loss=1.32\n",
      "2024-12-16 03:52:19,950 - INFO - Event: Step 1379/1803: training loss=0.95\n",
      "2024-12-16 03:52:19,951 - INFO - Event: Step 1378/1803: training loss=0.77\n",
      "2024-12-16 03:52:19,951 - INFO - Event: Step 1377/1803: training loss=0.78\n",
      "2024-12-16 03:52:19,952 - INFO - Event: Step 1376/1803: training loss=0.84\n",
      "2024-12-16 03:52:19,952 - INFO - Event: Step 1375/1803: training loss=0.00\n",
      "2024-12-16 03:52:19,953 - INFO - Event: Step 1374/1803: training loss=0.79\n",
      "2024-12-16 03:52:19,954 - INFO - Event: Step 1373/1803: training loss=0.76\n",
      "2024-12-16 03:52:19,954 - INFO - Event: Step 1372/1803: training loss=0.23\n",
      "2024-12-16 03:53:20,244 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:53:20,246 - INFO - Status: running\n",
      "2024-12-16 03:53:20,246 - INFO - Trained tokens: None\n",
      "2024-12-16 03:53:20,247 - INFO - Elapsed time: 33.33 minutes\n",
      "2024-12-16 03:53:20,463 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:53:20,465 - INFO - Event: Step 1430/1803: training loss=0.60\n",
      "2024-12-16 03:53:20,466 - INFO - Event: Step 1429/1803: training loss=0.62\n",
      "2024-12-16 03:53:20,466 - INFO - Event: Step 1428/1803: training loss=0.43\n",
      "2024-12-16 03:53:20,467 - INFO - Event: Step 1427/1803: training loss=0.56\n",
      "2024-12-16 03:53:20,468 - INFO - Event: Step 1426/1803: training loss=0.67\n",
      "2024-12-16 03:53:20,468 - INFO - Event: Step 1425/1803: training loss=0.00\n",
      "2024-12-16 03:53:20,469 - INFO - Event: Step 1424/1803: training loss=0.63\n",
      "2024-12-16 03:53:20,469 - INFO - Event: Step 1423/1803: training loss=0.75\n",
      "2024-12-16 03:53:20,470 - INFO - Event: Step 1422/1803: training loss=0.17\n",
      "2024-12-16 03:53:20,470 - INFO - Event: Step 1421/1803: training loss=0.72\n",
      "2024-12-16 03:54:20,740 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:54:20,745 - INFO - Status: running\n",
      "2024-12-16 03:54:20,748 - INFO - Trained tokens: None\n",
      "2024-12-16 03:54:20,750 - INFO - Elapsed time: 34.34 minutes\n",
      "2024-12-16 03:54:20,970 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:54:20,976 - INFO - Event: Step 1487/1803: training loss=1.02\n",
      "2024-12-16 03:54:20,977 - INFO - Event: Step 1486/1803: training loss=0.00\n",
      "2024-12-16 03:54:20,978 - INFO - Event: Step 1485/1803: training loss=0.44\n",
      "2024-12-16 03:54:20,979 - INFO - Event: Step 1484/1803: training loss=0.73\n",
      "2024-12-16 03:54:20,980 - INFO - Event: Step 1483/1803: training loss=0.24\n",
      "2024-12-16 03:54:20,981 - INFO - Event: Step 1482/1803: training loss=0.80\n",
      "2024-12-16 03:54:20,982 - INFO - Event: Step 1481/1803: training loss=0.81\n",
      "2024-12-16 03:54:20,982 - INFO - Event: Step 1480/1803: training loss=0.72\n",
      "2024-12-16 03:54:20,983 - INFO - Event: Step 1479/1803: training loss=0.84\n",
      "2024-12-16 03:54:20,984 - INFO - Event: Step 1478/1803: training loss=0.99\n",
      "2024-12-16 03:55:21,225 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:55:21,230 - INFO - Status: running\n",
      "2024-12-16 03:55:21,232 - INFO - Trained tokens: None\n",
      "2024-12-16 03:55:21,233 - INFO - Elapsed time: 35.35 minutes\n",
      "2024-12-16 03:55:21,436 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:55:21,442 - INFO - Event: Step 1543/1803: training loss=0.07\n",
      "2024-12-16 03:55:21,444 - INFO - Event: Step 1542/1803: training loss=0.63\n",
      "2024-12-16 03:55:21,445 - INFO - Event: Step 1541/1803: training loss=0.20\n",
      "2024-12-16 03:55:21,447 - INFO - Event: Step 1540/1803: training loss=0.71\n",
      "2024-12-16 03:55:21,448 - INFO - Event: Step 1539/1803: training loss=0.78\n",
      "2024-12-16 03:55:21,449 - INFO - Event: Step 1538/1803: training loss=0.66\n",
      "2024-12-16 03:55:21,449 - INFO - Event: Step 1537/1803: training loss=0.66\n",
      "2024-12-16 03:55:21,450 - INFO - Event: Step 1536/1803: training loss=0.46\n",
      "2024-12-16 03:55:21,451 - INFO - Event: Step 1535/1803: training loss=0.87\n",
      "2024-12-16 03:55:21,451 - INFO - Event: Step 1534/1803: training loss=0.77\n",
      "2024-12-16 03:56:21,803 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:56:21,808 - INFO - Status: running\n",
      "2024-12-16 03:56:21,811 - INFO - Trained tokens: None\n",
      "2024-12-16 03:56:21,812 - INFO - Elapsed time: 36.36 minutes\n",
      "2024-12-16 03:56:22,000 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:56:22,006 - INFO - Event: Step 1591/1803: training loss=0.77\n",
      "2024-12-16 03:56:22,008 - INFO - Event: Step 1590/1803: training loss=1.12\n",
      "2024-12-16 03:56:22,009 - INFO - Event: Step 1589/1803: training loss=0.79\n",
      "2024-12-16 03:56:22,010 - INFO - Event: Step 1588/1803: training loss=0.77\n",
      "2024-12-16 03:56:22,011 - INFO - Event: Step 1587/1803: training loss=0.76\n",
      "2024-12-16 03:56:22,011 - INFO - Event: Step 1586/1803: training loss=0.98\n",
      "2024-12-16 03:56:22,012 - INFO - Event: Step 1585/1803: training loss=0.75\n",
      "2024-12-16 03:56:22,013 - INFO - Event: Step 1584/1803: training loss=0.73\n",
      "2024-12-16 03:56:22,013 - INFO - Event: Step 1583/1803: training loss=0.64\n",
      "2024-12-16 03:56:22,014 - INFO - Event: Step 1582/1803: training loss=0.65\n",
      "2024-12-16 03:57:22,262 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:57:22,266 - INFO - Status: running\n",
      "2024-12-16 03:57:22,268 - INFO - Trained tokens: None\n",
      "2024-12-16 03:57:22,270 - INFO - Elapsed time: 37.36 minutes\n",
      "2024-12-16 03:57:22,476 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:57:22,483 - INFO - Event: Step 1647/1803: training loss=0.51\n",
      "2024-12-16 03:57:22,484 - INFO - Event: Step 1646/1803: training loss=0.72\n",
      "2024-12-16 03:57:22,485 - INFO - Event: Step 1645/1803: training loss=0.14\n",
      "2024-12-16 03:57:22,488 - INFO - Event: Step 1644/1803: training loss=0.53\n",
      "2024-12-16 03:57:22,489 - INFO - Event: Step 1643/1803: training loss=0.08\n",
      "2024-12-16 03:57:22,490 - INFO - Event: Step 1642/1803: training loss=0.00\n",
      "2024-12-16 03:57:22,490 - INFO - Event: Step 1641/1803: training loss=0.00\n",
      "2024-12-16 03:57:22,491 - INFO - Event: Step 1640/1803: training loss=0.80\n",
      "2024-12-16 03:57:22,491 - INFO - Event: Step 1639/1803: training loss=0.86\n",
      "2024-12-16 03:57:22,492 - INFO - Event: Step 1638/1803: training loss=0.00\n",
      "2024-12-16 03:58:22,738 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:58:22,742 - INFO - Status: running\n",
      "2024-12-16 03:58:22,743 - INFO - Trained tokens: None\n",
      "2024-12-16 03:58:22,743 - INFO - Elapsed time: 38.37 minutes\n",
      "2024-12-16 03:58:22,944 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:58:22,949 - INFO - Event: Step 1696/1803: training loss=0.60\n",
      "2024-12-16 03:58:22,950 - INFO - Event: Step 1695/1803: training loss=0.83\n",
      "2024-12-16 03:58:22,951 - INFO - Event: Step 1694/1803: training loss=0.68\n",
      "2024-12-16 03:58:22,951 - INFO - Event: Step 1693/1803: training loss=0.18\n",
      "2024-12-16 03:58:22,952 - INFO - Event: Step 1692/1803: training loss=0.04\n",
      "2024-12-16 03:58:22,952 - INFO - Event: Step 1691/1803: training loss=0.70\n",
      "2024-12-16 03:58:22,953 - INFO - Event: Step 1690/1803: training loss=0.73\n",
      "2024-12-16 03:58:22,953 - INFO - Event: Step 1689/1803: training loss=0.51\n",
      "2024-12-16 03:58:22,954 - INFO - Event: Step 1688/1803: training loss=0.04\n",
      "2024-12-16 03:58:22,954 - INFO - Event: Step 1687/1803: training loss=0.11\n",
      "2024-12-16 03:59:23,189 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:59:23,193 - INFO - Status: running\n",
      "2024-12-16 03:59:23,194 - INFO - Trained tokens: None\n",
      "2024-12-16 03:59:23,195 - INFO - Elapsed time: 39.38 minutes\n",
      "2024-12-16 03:59:23,389 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 03:59:23,393 - INFO - Event: Step 1757/1803: training loss=1.02\n",
      "2024-12-16 03:59:23,394 - INFO - Event: Step 1756/1803: training loss=0.38\n",
      "2024-12-16 03:59:23,395 - INFO - Event: Step 1755/1803: training loss=0.77\n",
      "2024-12-16 03:59:23,395 - INFO - Event: Step 1754/1803: training loss=1.08\n",
      "2024-12-16 03:59:23,396 - INFO - Event: Step 1753/1803: training loss=0.00\n",
      "2024-12-16 03:59:23,396 - INFO - Event: Step 1752/1803: training loss=0.03\n",
      "2024-12-16 03:59:23,397 - INFO - Event: Step 1751/1803: training loss=0.83\n",
      "2024-12-16 03:59:23,397 - INFO - Event: Step 1750/1803: training loss=0.81\n",
      "2024-12-16 03:59:23,398 - INFO - Event: Step 1749/1803: training loss=0.84\n",
      "2024-12-16 03:59:23,398 - INFO - Event: Step 1748/1803: training loss=0.78\n",
      "2024-12-16 04:00:23,696 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 04:00:23,701 - INFO - Status: running\n",
      "2024-12-16 04:00:23,703 - INFO - Trained tokens: None\n",
      "2024-12-16 04:00:23,704 - INFO - Elapsed time: 40.39 minutes\n",
      "2024-12-16 04:00:23,938 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 04:00:23,941 - INFO - Event: Step 1797/1803: training loss=0.80\n",
      "2024-12-16 04:00:23,941 - INFO - Event: Step 1796/1803: training loss=0.01\n",
      "2024-12-16 04:00:23,942 - INFO - Event: Step 1795/1803: training loss=0.11\n",
      "2024-12-16 04:00:23,943 - INFO - Event: Step 1794/1803: training loss=0.13\n",
      "2024-12-16 04:00:23,943 - INFO - Event: Step 1793/1803: training loss=0.71\n",
      "2024-12-16 04:00:23,944 - INFO - Event: Step 1792/1803: training loss=0.15\n",
      "2024-12-16 04:00:23,944 - INFO - Event: Step 1791/1803: training loss=0.75\n",
      "2024-12-16 04:00:23,945 - INFO - Event: Step 1790/1803: training loss=0.01\n",
      "2024-12-16 04:00:23,945 - INFO - Event: Step 1789/1803: training loss=0.21\n",
      "2024-12-16 04:00:23,946 - INFO - Event: Step 1788/1803: training loss=0.79\n",
      "2024-12-16 04:01:24,222 - INFO - HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-D6p43Lg4bP7TQlF0hKlv5Nxy \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 04:01:24,227 - INFO - Status: succeeded\n",
      "2024-12-16 04:01:24,228 - INFO - Trained tokens: 509928\n",
      "2024-12-16 04:01:24,230 - INFO - Elapsed time: 41.40 minutes\n",
      "2024-12-16 04:01:24,232 - INFO - Fine-tuning completed successfully!\n",
      "2024-12-16 04:01:24,233 - INFO - Model ID: ft:gpt-4o-mini-2024-07-18:personal::Af1GA1or\n",
      "2024-12-16 04:01:24,234 - INFO - Total training time: 41.40 minutes\n",
      "2024-12-16 04:01:24,235 - INFO - === Fine-Tuning Process Completed ===\n"
     ]
    }
   ],
   "source": [
    "# Start fine-tuning with enhanced error handling and progress tracking\n",
    "try:\n",
    "    logger.info(\"=== Starting Fine-Tuning Process ===\")\n",
    "    logger.info(f\"Training file: {combined_file}\")\n",
    "    \n",
    "    # Initialize fine-tuning\n",
    "    job_id, file_id = setup_fine_tuning(combined_file)\n",
    "    logger.info(f\"Training file ID: {file_id}\")\n",
    "    logger.info(f\"Fine-tuning job ID: {job_id}\")\n",
    "    \n",
    "    # Monitor progress\n",
    "    logger.info(\"Starting fine-tuning monitoring...\")\n",
    "    monitor_fine_tuning(job_id)\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Critical error during fine-tuning: {e}\")\n",
    "finally:\n",
    "    logger.info(\"=== Fine-Tuning Process Completed ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 04:15:59,732 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 04:16:01,173 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 04:16:01,881 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 04:16:03,009 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-16 04:16:04,337 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Results:\n",
      "\n",
      "Query: Explain GTO strategy in poker\n",
      "Response: GTO (Game Theory Optimal) strategy in poker is a balanced approach that aims to make your play unexploitable. It involves using a mixed strategy of various actions (betting, calling, folding) with dif...\n",
      "\n",
      "Query: What's the optimal 3-betting range from the button?\n",
      "Response: From the button, a strong 3-betting range could include: AA-22, AKs-A2s, AKo-AJo, KQs-KTs, QJs, JTs, T9s, 98s, 87s, 76s, 65s, 54s. This range balances value hands with numerous suited and connected bl...\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from datetime import datetime\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Initialize client\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Setup basic testing function\n",
    "def test_model_basic(model_id: str, test_queries: list):\n",
    "    \"\"\"\n",
    "    Perform initial basic testing of the fine-tuned model\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for query in test_queries:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_id,  # Your fine-tuned model\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert poker strategist.\"},\n",
    "                    {\"role\": \"user\", \"content\": query}\n",
    "                ],\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                \"query\": query,\n",
    "                \"response\": response.choices[0].message.content\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error testing query '{query}': {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Basic test queries\n",
    "test_queries = [\n",
    "    \"Explain GTO strategy in poker\",\n",
    "    \"What's the optimal 3-betting range from the button?\",\n",
    "    \"How should I approach multi-way pots?\",\n",
    "    \"Explain ICM considerations in tournament play\",\n",
    "    \"What's the correct strategy for playing AK preflop?\"\n",
    "]\n",
    "\n",
    "# Run initial tests\n",
    "model_id = \"ft:gpt-4o-mini-2024-07-18:personal::Af1GA1or\" \n",
    "results = test_model_basic(model_id, test_queries)\n",
    "\n",
    "# Save results\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "with open(f'../data/final/initial_test_results_{timestamp}.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "# Print sample results\n",
    "print(\"\\nSample Results:\")\n",
    "for result in results[:2]:  # Show first two results\n",
    "    print(f\"\\nQuery: {result['query']}\")\n",
    "    print(f\"Response: {result['response'][:200]}...\")  # First 200 chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model ID: ft:gpt-4o-mini-2024-07-18:personal::Af1GA1or"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
